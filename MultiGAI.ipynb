{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Jupyter notebook contains the source code for multimodal integration in the MultiGAI framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Distribution, Normal, constraints\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scanpy as sc\n",
    "from scipy.sparse import issparse\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set Python built-in random seed\n",
    "    random.seed(seed)  \n",
    "    \n",
    "    # Set NumPy random seed\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # Set PyTorch CPU random seed\n",
    "    torch.manual_seed(seed) \n",
    "    \n",
    "    # Set PyTorch GPU random seed (current device)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    \n",
    "    # Set PyTorch GPU random seed (all devices)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    \n",
    "    # Ensure deterministic behavior for CuDNN\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    \n",
    "    # Disable CuDNN auto-tuner to guarantee reproducibility\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroInflatedNegativeBinomial(Distribution):\n",
    "    \"\"\"\n",
    "    Zero-Inflated Negative Binomial (ZINB) distribution.\n",
    "\n",
    "    This distribution is commonly used to model over-dispersed count data\n",
    "    with excessive zeros, such as scRNA-seq gene expression counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constraints on distribution parameters\n",
    "    arg_constraints = {\n",
    "        \"mu\": constraints.greater_than_eq(0),      # Mean of the NB distribution\n",
    "        \"theta\": constraints.greater_than_eq(0),   # Inverse dispersion parameter\n",
    "        \"zi_logits\": constraints.real,              # Logits for zero-inflation probability\n",
    "        \"scale\": constraints.greater_than_eq(0),   # Optional scaling factor (e.g. library size)\n",
    "    }\n",
    "\n",
    "    # Support of the distribution: non-negative integers\n",
    "    support = constraints.nonnegative_integer\n",
    "\n",
    "    def __init__(self, mu, theta, zi_logits, scale, eps=1e-8, validate_args=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : torch.Tensor\n",
    "            Mean of the Negative Binomial distribution.\n",
    "        theta : torch.Tensor\n",
    "            Inverse dispersion parameter of the NB distribution.\n",
    "        zi_logits : torch.Tensor\n",
    "            Logits controlling the zero-inflation probability.\n",
    "        scale : torch.Tensor\n",
    "            Scaling factor applied to the mean (e.g. size factor).\n",
    "        eps : float\n",
    "            Small constant for numerical stability.\n",
    "        validate_args : bool\n",
    "            Whether to validate distribution arguments.\n",
    "        \"\"\"\n",
    "        self.mu = mu\n",
    "        self.theta = theta\n",
    "        self.zi_logits = zi_logits\n",
    "        self.scale = scale \n",
    "        self.eps = eps\n",
    "\n",
    "        # Initialize base Distribution class\n",
    "        super().__init__(validate_args=validate_args)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"\n",
    "        Compute log-probability of observed counts under ZINB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Observed count data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Log-likelihood of each observation.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert zero-inflation logits to probability\n",
    "        pi = torch.sigmoid(self.zi_logits)\n",
    "\n",
    "        # Log-probability under the Negative Binomial distribution\n",
    "        log_nb = (\n",
    "            torch.lgamma(x + self.theta)\n",
    "            - torch.lgamma(self.theta)\n",
    "            - torch.lgamma(x + 1)\n",
    "            + self.theta * torch.log(self.theta + self.eps)\n",
    "            + x * torch.log(self.mu + self.eps)\n",
    "            - (x + self.theta) * torch.log(self.mu + self.theta + self.eps)\n",
    "        )\n",
    "\n",
    "        # Zero-inflated mixture:\n",
    "        # - If x == 0: mixture of structural zero and NB zero\n",
    "        # - If x > 0: NB probability scaled by (1 - pi)\n",
    "        log_prob = torch.where(\n",
    "            (x == 0),\n",
    "            torch.log(pi + (1 - pi) * torch.exp(log_nb) + self.eps),\n",
    "            torch.log(1 - pi + self.eps) + log_nb,\n",
    "        )\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "class multigai(nn.Module):\n",
    "    \"\"\"\n",
    "    MultiGAI: A multi-modal generative integration model.\n",
    "\n",
    "    This model supports joint representation learning and cross-modality\n",
    "    reconstruction using attention-based latent fusion and ZINB decoders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim1,\n",
    "        input_dim2,\n",
    "        input_dim3,\n",
    "        n_hidden,\n",
    "        hidden,\n",
    "        z_dim,\n",
    "        batch_dim,\n",
    "        q_dim=128,\n",
    "        kv_n=64,\n",
    "        dropout_rate=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ===== Hyperparameters =====\n",
    "        self.kv_n = kv_n              # Number of key/value tokens\n",
    "        self.q_dim = q_dim            # Query embedding dimension\n",
    "        self.z_dim = z_dim            # Latent space dimension\n",
    "        self.batch_dim = batch_dim    # Batch covariate dimension\n",
    "        self.hidden = hidden          # Hidden layer width\n",
    "\n",
    "        # ===== Shared encoder constructor =====\n",
    "        def make_encoder(in_dim):\n",
    "            \"\"\"\n",
    "            Build a multi-layer MLP encoder with LayerNorm and Dropout.\n",
    "            \"\"\"\n",
    "            layers = []\n",
    "            for _ in range(n_hidden):\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_dim, hidden),\n",
    "                        nn.LayerNorm(hidden),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(dropout_rate)\n",
    "                    )\n",
    "                )\n",
    "                in_dim = hidden\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        # ===== Modality-specific encoders =====\n",
    "        self.encoder1 = make_encoder(input_dim1)\n",
    "        self.encoder2 = make_encoder(input_dim2)\n",
    "        self.encoder3 = make_encoder(input_dim3)\n",
    "\n",
    "        # ===== Projection to query space =====\n",
    "        self.q_net1 = nn.Linear(hidden, q_dim)\n",
    "        self.q_net2 = nn.Linear(hidden, q_dim)\n",
    "        self.q_net3 = nn.Linear(hidden, q_dim)\n",
    "\n",
    "        # ===== Key / Value network constructor =====\n",
    "        def make_kv(is_value):\n",
    "            \"\"\"\n",
    "            Build key/value networks for attention-based latent fusion.\n",
    "            \"\"\"\n",
    "            layers = []\n",
    "            in_dim = kv_n\n",
    "            for _ in range(n_hidden):\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_dim, hidden),\n",
    "                        nn.LayerNorm(hidden),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(dropout_rate)\n",
    "                    )\n",
    "                )\n",
    "                in_dim = hidden\n",
    "            if not is_value:\n",
    "                layers.append(nn.Linear(hidden, q_dim))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        # ===== Modality-specific key/value banks =====\n",
    "        self.keys1 = make_kv(is_value=False)\n",
    "        self.values1 = make_kv(is_value=True)\n",
    "        self.keys2 = make_kv(is_value=False)\n",
    "        self.values2 = make_kv(is_value=True)\n",
    "        self.keys3 = make_kv(is_value=False)\n",
    "        self.values3 = make_kv(is_value=True)\n",
    "\n",
    "        # ===== Shared key/value banks =====\n",
    "        self.keys = make_kv(is_value=False)\n",
    "        self.values = make_kv(is_value=True)\n",
    "\n",
    "        # ===== Latent Gaussian parameter heads =====\n",
    "        self.m_net = nn.Linear(hidden, z_dim)   # Mean of q(z|x)\n",
    "        self.l_net = nn.Linear(hidden, z_dim)   # Log-variance of q(z|x)\n",
    "\n",
    "        # ===== Shared decoder backbone =====\n",
    "        self.decoder_base = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(z_dim + batch_dim if i == 0 else hidden + batch_dim, hidden),\n",
    "                nn.LayerNorm(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ) for i in range(n_hidden)\n",
    "        ])\n",
    "\n",
    "        # ===== ZINB decoders for each modality =====\n",
    "        # Modality 1\n",
    "        self.fc_scale1 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim1),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Linear(hidden + batch_dim, input_dim1)\n",
    "        self.fc_r1 = nn.Parameter(torch.randn(input_dim1))  # Dispersion\n",
    "\n",
    "        # Modality 2\n",
    "        self.fc_scale2 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim2),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout2 = nn.Linear(hidden + batch_dim, input_dim2)\n",
    "        self.fc_r2 = nn.Parameter(torch.randn(input_dim2))\n",
    "\n",
    "        # Modality 3\n",
    "        self.fc_scale3 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout3 = nn.Linear(hidden + batch_dim, input_dim3)\n",
    "        self.fc_r3 = nn.Parameter(torch.randn(input_dim3))\n",
    "\n",
    "    def compute_mu_var(self, device, q1=None, q2=None, q3=None, m=None):\n",
    "        \"\"\"\n",
    "        Compute latent mean and variance using attention-based fusion\n",
    "        of modality-specific query embeddings.\n",
    "        \"\"\"\n",
    "        I = torch.eye(self.kv_n, device=device)   # Identity tokens\n",
    "        scale = math.sqrt(self.q_dim)\n",
    "\n",
    "        attn1 = attn2 = attn3 = None\n",
    "\n",
    "        # ===== Modality-pair attention fusion =====\n",
    "        if m == 12:\n",
    "            ker1, val1 = self.keys1(I), self.values1(I)\n",
    "            ker2, val2 = self.keys2(I), self.values2(I)\n",
    "\n",
    "            attn1 = torch.softmax((q1 @ ker1.T) / scale, dim=-1) @ val1\n",
    "            attn2 = torch.softmax((q2 @ ker2.T) / scale, dim=-1) @ val2\n",
    "\n",
    "            ae = (attn1 + attn2) / 2.0\n",
    "\n",
    "        elif m == 13:\n",
    "            ker1, val1 = self.keys1(I), self.values1(I)\n",
    "            ker3, val3 = self.keys3(I), self.values3(I)\n",
    "\n",
    "            attn1 = torch.softmax((q1 @ ker1.T) / scale, dim=-1) @ val1\n",
    "            attn3 = torch.softmax((q3 @ ker3.T) / scale, dim=-1) @ val3\n",
    "\n",
    "            ae = (attn1 + attn3) / 2.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported modality m={m}\")\n",
    "\n",
    "        # ===== Shared attention refinement =====\n",
    "        ker, val = self.keys(I), self.values(I)\n",
    "        attn = torch.softmax((ae @ ker.T) / scale, dim=-1) @ val\n",
    "\n",
    "        # ===== Latent Gaussian parameters =====\n",
    "        mu = self.m_net(attn)\n",
    "        logvar = self.l_net(attn)\n",
    "        var = torch.exp(logvar) + 1e-8\n",
    "\n",
    "        return mu, var, attn1, attn2, attn3, ae, attn\n",
    "\n",
    "    def decode_from_z(self, dz, m1, m2, m3, m, batch):\n",
    "        \"\"\"\n",
    "        Decode latent variables into modality-specific ZINB distributions.\n",
    "        \"\"\"\n",
    "        for layer in self.decoder_base:\n",
    "            dz = torch.cat([dz, batch], dim=1)\n",
    "            dz = layer(dz)\n",
    "\n",
    "        final = torch.cat([dz, batch], dim=1)\n",
    "\n",
    "        p1 = p2 = p3 = None\n",
    "\n",
    "        if m in [12, 13]:\n",
    "            # ===== Modality 1 =====\n",
    "            scale1 = self.fc_scale1(final)\n",
    "            dropout1 = self.fc_dropout1(final)\n",
    "            library1 = torch.log(m1.sum(1, keepdim=True) + 1e-8)\n",
    "            rate1 = torch.exp(library1) * scale1\n",
    "\n",
    "            p1 = ZeroInflatedNegativeBinomial(\n",
    "                mu=rate1,\n",
    "                theta=torch.exp(self.fc_r1),\n",
    "                zi_logits=dropout1,\n",
    "                scale=scale1\n",
    "            )\n",
    "\n",
    "            # ===== Modality 2 =====\n",
    "            if m == 12:\n",
    "                scale2 = self.fc_scale2(final)\n",
    "                dropout2 = self.fc_dropout2(final)\n",
    "                library2 = torch.log(m2.sum(1, keepdim=True) + 1e-8)\n",
    "                rate2 = torch.exp(library2) * scale2\n",
    "\n",
    "                p2 = ZeroInflatedNegativeBinomial(\n",
    "                    mu=rate2,\n",
    "                    theta=torch.exp(self.fc_r2),\n",
    "                    zi_logits=dropout2,\n",
    "                    scale=scale2\n",
    "                )\n",
    "\n",
    "            # ===== Modality 3 =====\n",
    "            if m == 13:\n",
    "                scale3 = self.fc_scale3(final)\n",
    "                dropout3 = self.fc_dropout3(final)\n",
    "                library3 = torch.log(m3.sum(1, keepdim=True) + 1e-8)\n",
    "                rate3 = torch.exp(library3) * scale3\n",
    "\n",
    "                p3 = ZeroInflatedNegativeBinomial(\n",
    "                    mu=rate3,\n",
    "                    theta=torch.exp(self.fc_r3),\n",
    "                    zi_logits=dropout3,\n",
    "                    scale=scale3\n",
    "                )\n",
    "\n",
    "        return p1, p2, p3\n",
    "\n",
    "    def forward(self, m1, m2, m3, m, batch):\n",
    "        \"\"\"\n",
    "        Forward pass of MultiGAI.\n",
    "        \"\"\"\n",
    "        device = batch.device\n",
    "        batch_size = m1.size(0)\n",
    "\n",
    "        # ===== Encode =====\n",
    "        q1 = q2 = q3 = None\n",
    "        if m in [12, 13]:\n",
    "            e1 = self.encoder1(m1)\n",
    "            q1 = self.q_net1(e1)\n",
    "\n",
    "            if m == 12:\n",
    "                e2 = self.encoder2(m2)\n",
    "                q2 = self.q_net2(e2)\n",
    "\n",
    "            if m == 13:\n",
    "                e3 = self.encoder3(m3)\n",
    "                q3 = self.q_net3(e3)\n",
    "\n",
    "        # ===== Latent inference =====\n",
    "        mu, var, a1, a2, a3, aq, ae = self.compute_mu_var(device, q1, q2, q3, m)\n",
    "        var = torch.clamp(var, min=1e-6)\n",
    "\n",
    "        qz = Normal(mu, var.sqrt())\n",
    "        z = qz.rsample()\n",
    "        pz = Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "\n",
    "        # ===== Decode =====\n",
    "        p1, p2, p3 = self.decode_from_z(z, m1, m2, m3, m, batch)\n",
    "\n",
    "        return z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae\n",
    "\n",
    "    def loss_function(self, m1, m2, m3, m, p1, p2, p3, q, p, a1, a2, a3, w):\n",
    "        \"\"\"\n",
    "        Compute total loss:\n",
    "        reconstruction + KL divergence + cosine alignment loss.\n",
    "        \"\"\"\n",
    "        device = m1.device\n",
    "        cos_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        if m == 12:\n",
    "            reconst_loss = (\n",
    "                -p1.log_prob(m1).sum(-1).mean()\n",
    "                -p2.log_prob(m2).sum(-1).mean()\n",
    "            )\n",
    "            cos_loss = (1 - F.cosine_similarity(a1, a2, dim=1)).mean()\n",
    "\n",
    "        elif m == 13:\n",
    "            reconst_loss = (\n",
    "                -p1.log_prob(m1).sum(-1).mean()\n",
    "                -p3.log_prob(m3).sum(-1).mean()\n",
    "            )\n",
    "            cos_loss = (1 - F.cosine_similarity(a1, a3, dim=1)).mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported modality m={m}\")\n",
    "\n",
    "        kl = torch.distributions.kl_divergence(q, p).sum(dim=-1).mean()\n",
    "\n",
    "        loss = reconst_loss + w * kl + cos_loss\n",
    "        return loss, reconst_loss, kl, cos_loss\n",
    "    \n",
    "class MultiOmicsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for multi-omics data.\n",
    "\n",
    "    Each sample contains:\n",
    "    - Three modality feature vectors (m1, m2, m3)\n",
    "    - A modality indicator m\n",
    "    - A batch covariate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.m1_data = args[0]     # Modality 1 data (e.g., scRNA-seq)\n",
    "        self.m2_data = args[1]     # Modality 2 data (e.g., scATAC-seq)\n",
    "        self.m3_data = args[2]     # Modality 3 data (e.g., ADT)\n",
    "        self.m_data = args[3]      # Modality indicator (12 or 13)\n",
    "        self.batch_data = args[4]  # Batch labels / covariates\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of samples\n",
    "        return len(self.batch_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert each modality to float tensor\n",
    "        m1 = torch.tensor(self.m1_data[idx], dtype=torch.float32).squeeze(0)\n",
    "        m2 = torch.tensor(self.m2_data[idx], dtype=torch.float32).squeeze(0)\n",
    "        m3 = torch.tensor(self.m3_data[idx], dtype=torch.float32).squeeze(0)\n",
    "\n",
    "        # Modality combination indicator\n",
    "        m = torch.tensor(self.m_data[idx], dtype=torch.float32).squeeze(0)\n",
    "\n",
    "        # Batch covariate\n",
    "        batch = self.batch_data[idx]\n",
    "\n",
    "        return m1, m2, m3, m, batch, idx\n",
    "\n",
    "def train_and_evaluate_model(\n",
    "    output_path,\n",
    "    train_loader,\n",
    "    test_loader,\n",
    "    adata,\n",
    "    *args,\n",
    "    num_epochs=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the MultiGAI model and extract latent representations.\n",
    "\n",
    "    The final latent embeddings are stored in adata.obsm['latent'].\n",
    "    \"\"\"\n",
    "\n",
    "    # Select training device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Unpack model hyperparameters\n",
    "    input_dim1, input_dim2, input_dim3, n_hidden, hidden, z_dim, batch_dim, q_dim, kv_n = args\n",
    "\n",
    "    # Initialize model\n",
    "    model = multigai(\n",
    "        input_dim1, input_dim2, input_dim3,\n",
    "        n_hidden, hidden, z_dim,\n",
    "        batch_dim, q_dim, kv_n\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer and learning rate scheduler\n",
    "    optimizer_main = Adam(model.parameters(), lr=0.001)\n",
    "    scheduler_main = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer_main, step_size=50, gamma=0.9\n",
    "    )\n",
    "\n",
    "    # Progress bar\n",
    "    tqdm_bar = tqdm(range(num_epochs), desc=\"Training Progress\")\n",
    "\n",
    "    # ===== Training loop =====\n",
    "    for epoch in tqdm_bar:\n",
    "        running_loss = 0.0\n",
    "        running_recon = 0.0\n",
    "        running_kl = 0.0\n",
    "        running_cos = 0.0\n",
    "\n",
    "        # KL annealing schedule\n",
    "        kl_weight = 0.0 if epoch < 100 else 0.1\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            optimizer_main.zero_grad()\n",
    "\n",
    "            # Extract modality indicators for the batch\n",
    "            m_values = batch_data[3]\n",
    "            unique_m = m_values.unique()\n",
    "\n",
    "            # Randomize modality processing order\n",
    "            perm = torch.randperm(len(unique_m))\n",
    "            unique_m = unique_m[perm]\n",
    "\n",
    "            # Process each modality combination separately\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "\n",
    "                if mask.any():\n",
    "                    # Sub-batch corresponding to the current modality\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, m_tensor, batch_tensor, idx = [\n",
    "                        x.to(device) for x in sub_batch\n",
    "                    ]\n",
    "\n",
    "                    # Forward pass\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3,\n",
    "                        int(m_curr.item()),\n",
    "                        batch_tensor\n",
    "                    )\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss, reconst_loss, kl_loss, cos_loss = model.loss_function(\n",
    "                        m1, m2, m3,\n",
    "                        int(m_curr.item()),\n",
    "                        p1, p2, p3,\n",
    "                        qz, pz,\n",
    "                        a1, a2, a3,\n",
    "                        kl_weight\n",
    "                    )\n",
    "\n",
    "                    # Backpropagation and optimization\n",
    "                    loss.backward()\n",
    "                    optimizer_main.step()\n",
    "\n",
    "                    # Accumulate metrics\n",
    "                    running_loss += loss.item()\n",
    "                    running_recon += reconst_loss.item()\n",
    "                    running_kl += kl_loss.item()\n",
    "                    running_cos += cos_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        n_batches = len(train_loader)\n",
    "        tqdm_bar.set_postfix({\n",
    "            \"loss\": f\"{running_loss / n_batches:.4f}\",\n",
    "            \"recon\": f\"{running_recon / n_batches:.4f}\",\n",
    "            \"kl\": f\"{running_kl / n_batches:.4f}\",\n",
    "            \"cos\": f\"{running_cos / n_batches:.4f}\",\n",
    "            \"w\": f\"{kl_weight:.3f}\"\n",
    "        })\n",
    "\n",
    "        scheduler_main.step()\n",
    "\n",
    "    # ===== Evaluation and latent extraction =====\n",
    "    model.eval()\n",
    "    z_all = torch.zeros((len(adata), z_dim), device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test_loader:\n",
    "            indices = batch_data[-1]\n",
    "            m_values = batch_data[3]\n",
    "            unique_m = m_values.unique()\n",
    "\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, m_tensor, batch_tensor, idx = [\n",
    "                        x.to(device) for x in sub_batch\n",
    "                    ]\n",
    "\n",
    "                    # Encode to latent space\n",
    "                    z, _, _, _, _, _, _, _, _, _, _ = model(\n",
    "                        m1, m2, m3,\n",
    "                        int(m_curr.item()),\n",
    "                        batch_tensor\n",
    "                    )\n",
    "\n",
    "                    # Store latent embeddings at original indices\n",
    "                    z_all[idx.long()] = z\n",
    "\n",
    "    # Save latent representation to AnnData\n",
    "    adata.obsm['latent'] = z_all.cpu().numpy()\n",
    "    adata.write_h5ad(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load Multiome single-cell data (RNA + ATAC)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and ATAC datasets\n",
    "rna = sc.read(\"./data/neurips-multiome/rna_hvg.h5ad\") \n",
    "atac = sc.read(\"./data/neurips-multiome/atac_hvf.h5ad\") \n",
    "\n",
    "# Keep only cells with Modality equal to 'multiome'\n",
    "rna = rna[rna.obs['Modality'] == 'multiome']\n",
    "\n",
    "# Extract raw count matrices for RNA and ATAC\n",
    "rna_d, atac_d = rna.layers['counts'], atac.layers['counts'] \n",
    "\n",
    "# Create a placeholder matrix for ADT (protein) data (not present in Multiome dataset)\n",
    "adt_d = np.zeros((rna_d.shape[0], 1))  \n",
    "\n",
    "# Record feature dimensions for each modality\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1  \n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(atac_d): atac_d = atac_d.toarray() \n",
    "\n",
    "# Construct modality vector (all cells are Multiome)\n",
    "modality_vector = np.full(rna.shape[0], 12.0)  # 12 corresponds to Multiome\n",
    "\n",
    "# Encode batch information as one-hot vectors for batch effect correction\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build the integrated Multi-Omics dataset\n",
    "# Includes RNA, ATAC, ADT (placeholder), modality, and batch information\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_vector, batch_encoded) \n",
    "\n",
    "# Create training and testing DataLoaders\n",
    "train_loader = DataLoader(dataset, batch_size=512, shuffle=True) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: The `rna` object passed here is NOT used for training.\n",
    "#       It only provides metadata (.obs) and serves as the template\n",
    "#       to save the learned latent variables into a .h5ad file.\n",
    "#       The model integrates Multiome data (RNA + ATAC),\n",
    "#       supports batch effect correction, and outputs a unified latent representation\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-multiome-multigai_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only used to save latent variables, not for training\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for all neural network components (encoder & decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention\n",
    "    128,        # Decoder hidden dimension (can be same as above if shared)\n",
    "    128         # Number of key-value (K-V) pairs in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load CITE-seq single-cell data (RNA + ADT)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and protein (ADT) datasets\n",
    "rna = sc.read(\"./data/neurips-cite/rna_hvg.h5ad\") \n",
    "adt = sc.read(\"./data/neurips-cite/protein.h5ad\") \n",
    "\n",
    "# Extract raw count matrices for RNA and ADT\n",
    "rna_d, adt_d = rna.layers['counts'], adt.layers['counts'] \n",
    "\n",
    "# Create a placeholder matrix for ATAC (not present in CITE-seq dataset)\n",
    "atac_d = np.zeros((rna_d.shape[0], 1))  \n",
    "\n",
    "# Record feature dimensions for each modality\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], 1, adt.shape[1]  \n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(adt_d): adt_d = adt_d.toarray() \n",
    "\n",
    "# Construct modality vector to distinguish Multiome and CITE-seq data\n",
    "modality_map = { 'multiome': 12, 'cite': 13} \n",
    "modality_vector = rna.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Encode batch information as one-hot vectors for batch effect correction\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build the integrated Multi-Omics dataset\n",
    "# Includes RNA, ATAC (placeholder), ADT, modality, and batch information\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded) \n",
    "\n",
    "# Create training and testing DataLoaders\n",
    "train_loader = DataLoader(dataset, batch_size=512, shuffle=True) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: The `rna` object passed here is NOT used for training.\n",
    "#       It only provides metadata (.obs) and serves as the template\n",
    "#       to save the learned latent variables into a .h5ad file.\n",
    "#       The model integrates CITE-seq data (RNA + ADT),\n",
    "#       supports batch effect correction, and outputs a unified latent representation\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-cite-multigai_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only used to save latent variables, not for training\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for the entire network (encoder + decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention mechanism\n",
    "    128,        # Decoder hidden dimension (if different from shared hidden layers)\n",
    "    128         # Number of key-value (K-V) pairs used in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load Multiome single-cell data (RNA + ATAC)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and ATAC datasets\n",
    "rna = sc.read(\"./data/neurips-multiome/rna_hvg.h5ad\") \n",
    "atac = sc.read(\"./data/neurips-multiome/atac_hvf.h5ad\") \n",
    "\n",
    "# ================= Training data (exclude NK cells) =================\n",
    "# Select only cells that are NOT NK cells\n",
    "rna_t = rna[rna.obs_names[rna.obs[\"cell_type\"] != \"NK\"]].copy() \n",
    "atac_t = atac[atac.obs_names[atac.obs[\"cell_type\"] != \"NK\"]].copy() \n",
    "\n",
    "# Extract raw count matrices\n",
    "rna_t_d, atac_t_d = rna_t.layers['counts'], atac_t.layers['counts'] \n",
    "\n",
    "# Placeholder for ADT (not present in Multiome)\n",
    "adt_t_d = np.zeros((rna_t_d.shape[0], 1))  \n",
    "\n",
    "# Feature dimensions\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1 \n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_t_d): rna_t_d = rna_t_d.toarray() \n",
    "if issparse(atac_t_d): atac_t_d = atac_t_d.toarray() \n",
    "\n",
    "# Construct modality vector (all cells are Multiome)\n",
    "modality_map = { 'multiome': 12, 'cite': 13} \n",
    "modality_vector = rna_t.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Encode batch information as one-hot\n",
    "batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build training dataset\n",
    "dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded) \n",
    "train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True) \n",
    "\n",
    "# ================= Test data (all cells, including NK) =================\n",
    "rna_d, atac_d = rna.layers['counts'], atac.layers['counts'] \n",
    "adt_d = np.zeros((rna_d.shape[0], 1))  \n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1 \n",
    "\n",
    "# Convert sparse to dense if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(atac_d): atac_d = atac_d.toarray() \n",
    "\n",
    "# Modality vector\n",
    "modality_vector = rna.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Batch encoding\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build testing dataset\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: `rna` is only used to save latent variables and provide metadata (.obs)\n",
    "#       The model is trained on cells excluding NK (train_loader)\n",
    "#       and evaluated on all cells including NK (test_loader)\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-multiome-NK_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only for saving latent variables and metadata\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for the entire network (encoder + decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention mechanism\n",
    "    128,        # Decoder hidden dimension (if different from shared hidden layers)\n",
    "    128         # Number of key-value (K-V) pairs used in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load Multiome single-cell data (RNA + ATAC)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and ATAC datasets\n",
    "rna = sc.read(\"./data/neurips-multiome/rna_hvg.h5ad\") \n",
    "atac = sc.read(\"./data/neurips-multiome/atac_hvf.h5ad\") \n",
    "\n",
    "# ================= Training data (exclude Lymph prog cells) =================\n",
    "# Select only cells that are NOT Lymph prog\n",
    "rna_t = rna[rna.obs_names[rna.obs[\"cell_type\"] != \"Lymph prog\"]].copy() \n",
    "atac_t = atac[atac.obs_names[atac.obs[\"cell_type\"] != \"Lymph prog\"]].copy() \n",
    "\n",
    "# Extract raw count matrices\n",
    "rna_t_d, atac_t_d = rna_t.layers['counts'], atac_t.layers['counts'] \n",
    "\n",
    "# Placeholder for ADT (not present in Multiome)\n",
    "adt_t_d = np.zeros((rna_t_d.shape[0], 1))  \n",
    "\n",
    "# Feature dimensions\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1 \n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_t_d): rna_t_d = rna_t_d.toarray() \n",
    "if issparse(atac_t_d): atac_t_d = atac_t_d.toarray() \n",
    "\n",
    "# Construct modality vector (all cells are Multiome)\n",
    "modality_map = { 'multiome': 12, 'cite': 13} \n",
    "modality_vector = rna_t.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Encode batch information as one-hot\n",
    "batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build training dataset\n",
    "dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded) \n",
    "train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True) \n",
    "\n",
    "# ================= Test data (all cells, including Lymph prog) =================\n",
    "rna_d, atac_d = rna.layers['counts'], atac.layers['counts'] \n",
    "adt_d = np.zeros((rna_d.shape[0], 1))  \n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1 \n",
    "\n",
    "# Convert sparse to dense if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(atac_d): atac_d = atac_d.toarray() \n",
    "\n",
    "# Modality vector\n",
    "modality_vector = rna.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Batch encoding\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build testing dataset\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: `rna` is only used to save latent variables and provide metadata (.obs)\n",
    "#       The model is trained on cells excluding Lymph prog (train_loader)\n",
    "#       and evaluated on all cells including Lymph prog (test_loader)\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-multiome-Lymphprog_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only for saving latent variables and metadata\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for the entire network (encoder + decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention mechanism\n",
    "    128,        # Decoder hidden dimension (if different from shared hidden layers)\n",
    "    128         # Number of key-value (K-V) pairs used in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load CITE-seq single-cell data (RNA + ADT)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and protein (ADT) datasets\n",
    "rna = sc.read(\"./data/neurips-cite/rna_hvg.h5ad\")\n",
    "adt = sc.read(\"./data/neurips-cite/protein.h5ad\")\n",
    "\n",
    "# ================= Training data (exclude CD8+ T naive cells) =================\n",
    "# Select only cells that are NOT CD8+ T naive\n",
    "rna_t  = rna[rna.obs_names[rna.obs[\"cell_type\"] != \"CD8+ T naive\"]].copy()\n",
    "adt_t = adt[adt.obs_names[adt.obs[\"cell_type\"] != \"CD8+ T naive\"]].copy()\n",
    "\n",
    "# Extract raw count matrices\n",
    "rna_t_d, adt_t_d = rna_t.layers['counts'], adt_t.layers['counts']\n",
    "\n",
    "# Placeholder for ATAC (not present in CITE-seq)\n",
    "atac_t_d = np.zeros((rna_t_d.shape[0], 1))  \n",
    "\n",
    "# Feature dimensions\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], 1, adt.shape[1]\n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_t_d): rna_t_d = rna_t_d.toarray()\n",
    "if issparse(adt_t_d): adt_t_d = adt_t_d.toarray()  \n",
    "\n",
    "# Construct modality vector (all cells are CITE-seq)\n",
    "modality_map = { 'multiome': 12, 'cite': 13} \n",
    "modality_vector = rna_t.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Encode batch information as one-hot\n",
    "batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build training dataset\n",
    "dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded) \n",
    "train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True) \n",
    "\n",
    "# ================= Test data (all cells, including CD8+ T naive) =================\n",
    "rna_d, adt_d = rna.layers['counts'], adt.layers['counts'] \n",
    "atac_d = np.zeros((rna_d.shape[0], 1))  \n",
    "\n",
    "# Convert sparse to dense if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(adt_d): adt_d = adt_d.toarray() \n",
    "\n",
    "# Modality vector\n",
    "modality_vector = rna.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Batch encoding\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build testing dataset\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: `rna` is only used to save latent variables and provide metadata (.obs)\n",
    "#       The model is trained on cells excluding CD8+ T naive (train_loader)\n",
    "#       and evaluated on all cells including CD8+ T naive (test_loader)\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-cite-CD8+Tnaive_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only for saving latent variables and metadata\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for the entire network (encoder + decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention mechanism\n",
    "    128,        # Decoder hidden dimension (if different from shared hidden layers)\n",
    "    128         # Number of key-value (K-V) pairs used in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================\n",
    "# Load CITE-seq single-cell data (RNA + ADT)\n",
    "# ================================================\n",
    "\n",
    "# Load RNA and protein (ADT) datasets\n",
    "rna = sc.read(\"./data/neurips-cite/rna_hvg.h5ad\")\n",
    "adt = sc.read(\"./data/neurips-cite/protein.h5ad\")\n",
    "\n",
    "# ================= Training data (exclude HSC cells) =================\n",
    "# Select only cells that are NOT HSC\n",
    "rna_t  = rna[rna.obs_names[rna.obs[\"cell_type\"] != \"HSC\"]].copy()\n",
    "adt_t = adt[adt.obs_names[adt.obs[\"cell_type\"] != \"HSC\"]].copy()\n",
    "\n",
    "# Extract raw count matrices\n",
    "rna_t_d, adt_t_d = rna_t.layers['counts'], adt_t.layers['counts']\n",
    "\n",
    "# Placeholder for ATAC (not present in CITE-seq)\n",
    "atac_t_d = np.zeros((rna_t_d.shape[0], 1))  \n",
    "\n",
    "# Feature dimensions\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], 1, adt.shape[1]\n",
    "\n",
    "# Convert sparse matrices to dense arrays if needed\n",
    "if issparse(rna_t_d): rna_t_d = rna_t_d.toarray()\n",
    "if issparse(adt_t_d): adt_t_d = adt_t_d.toarray()  \n",
    "\n",
    "# Construct modality vector (all cells are CITE-seq)\n",
    "modality_map = { 'multiome': 12, 'cite': 13} \n",
    "modality_vector = rna_t.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Encode batch information as one-hot\n",
    "batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build training dataset\n",
    "dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded) \n",
    "train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True) \n",
    "\n",
    "# ================= Test data (all cells, including HSC) =================\n",
    "rna_d, adt_d = rna.layers['counts'], adt.layers['counts'] \n",
    "atac_d = np.zeros((rna_d.shape[0], 1))  \n",
    "\n",
    "# Convert sparse to dense if needed\n",
    "if issparse(rna_d): rna_d = rna_d.toarray() \n",
    "if issparse(adt_d): adt_d = adt_d.toarray() \n",
    "\n",
    "# Modality vector\n",
    "modality_vector = rna.obs['Modality'].map(modality_map) \n",
    "modality_d = modality_vector.to_numpy().astype(float) \n",
    "\n",
    "# Batch encoding\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long() \n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices) \n",
    "batch_dim = batch_encoded.shape[1] \n",
    "\n",
    "# Build testing dataset\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded) \n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False) \n",
    "\n",
    "# ================================================\n",
    "# Train and evaluate the MultiGAI model\n",
    "# Note: `rna` is only used to save latent variables and provide metadata (.obs)\n",
    "#       The model is trained on cells excluding HSC (train_loader)\n",
    "#       and evaluated on all cells including HSC (test_loader)\n",
    "# ================================================\n",
    "train_and_evaluate_model(\n",
    "    './results/neurips-cite-HSC_latent.h5ad',\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    rna,  # Only for saving latent variables and metadata\n",
    "    rna_dim, \n",
    "    atac_dim, \n",
    "    adt_dim, \n",
    "    1,          # Number of hidden layers for the entire network (encoder + decoder)\n",
    "    128,        # Hidden dimension for all layers in the network\n",
    "    30,         # Latent dimension\n",
    "    batch_dim,  # Dimension of the query vector (q) in attention mechanism\n",
    "    128,        # Decoder hidden dimension (if different from shared hidden layers)\n",
    "    128         # Number of key-value (K-V) pairs used in attention\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna = sc.read('./data/trimodal_rna.h5ad')\n",
    "atac = sc.read('./data/trimodal_atac.h5ad')\n",
    "adt = sc.read('./data/trimodal_adt.h5ad')\n",
    "\n",
    "t_dir = \"./results\"\n",
    "\n",
    "rna_d, atac_d, adt_d = rna.layers['counts'], atac.layers['counts'], adt.layers['counts']\n",
    "rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], adt.shape[1]\n",
    "if issparse(rna_d): rna_d = rna_d.toarray()\n",
    "if issparse(atac_d): atac_d = atac_d.toarray()\n",
    "if issparse(adt_d): adt_d = adt_d.toarray() \n",
    "modality_map = {'multiome': 12,'cite': 13}\n",
    "modality_vector = rna.obs['Modality'].map(modality_map)\n",
    "modality_d = modality_vector.to_numpy().astype(float)\n",
    "batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long()\n",
    "batch_encoded = torch.nn.functional.one_hot(batch_indices)\n",
    "batch_dim = batch_encoded.shape[1]\n",
    "dataset = MultiOmicsDataset(rna_d, atac_d, adt_d, modality_d, batch_encoded)\n",
    "train_loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "\n",
    "output_path = './results/trimodal.h5ad'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "adata, input_dim1, input_dim2, input_dim3, n_hidden, hidden, z_dim, batch_dim, q_dim, kv_n = rna, rna_dim, atac_dim, adt_dim, 1, 128, 30, batch_dim, 128, 128\n",
    "model = multigai(input_dim1, input_dim2, input_dim3,\n",
    "                    n_hidden, hidden, z_dim,\n",
    "                    batch_dim, q_dim, kv_n).to(device)\n",
    "\n",
    "optimizer_main = Adam(model.parameters(), lr=0.001)\n",
    "scheduler_main = torch.optim.lr_scheduler.StepLR(optimizer_main, step_size=50, gamma=0.9)\n",
    "tqdm_bar = tqdm(range(200), desc=\"Training Progress\")\n",
    "\n",
    "for epoch in tqdm_bar:\n",
    "    running_loss = 0.0\n",
    "    running_recon = 0.0\n",
    "    running_kl = 0.0\n",
    "    running_cos = 0.0\n",
    "\n",
    "    kl_weight = 0.0 if epoch < 100 else 0.1\n",
    "\n",
    "    model.train()\n",
    "    for batch_data in train_loader:\n",
    "        optimizer_main.zero_grad()\n",
    "\n",
    "        m_values = batch_data[3]                       \n",
    "        unique_m = m_values.unique()\n",
    "\n",
    "        perm = torch.randperm(len(unique_m))\n",
    "        unique_m = unique_m[perm]\n",
    "\n",
    "        for m_curr in unique_m:\n",
    "            mask = (m_values == m_curr)\n",
    "\n",
    "            if mask.any():\n",
    "                sub_batch = [d[mask] for d in batch_data]\n",
    "                m1, m2, m3, m_tensor, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "                z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                    m1, m2, m3,\n",
    "                    int(m_curr.item()),\n",
    "                    batch_tensor\n",
    "                )\n",
    "\n",
    "                loss, reconst_loss, kl_loss, cos_loss = model.loss_function(\n",
    "                    m1, m2, m3,\n",
    "                    int(m_curr.item()),\n",
    "                    p1, p2, p3, qz, pz,\n",
    "                    a1, a2, a3,\n",
    "                    kl_weight\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer_main.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_recon += reconst_loss.item()\n",
    "                running_kl += kl_loss.item()\n",
    "                running_cos += cos_loss.item()\n",
    "\n",
    "    n_batches = len(train_loader)\n",
    "    tqdm_bar.set_postfix({\n",
    "        \"loss\": f\"{running_loss/n_batches:.4f}\",\n",
    "        \"recon\": f\"{running_recon/n_batches:.4f}\",\n",
    "        \"kl\": f\"{running_kl/n_batches:.4f}\",\n",
    "        \"cos\": f\"{running_cos/n_batches:.4f}\",\n",
    "        \"w\": f\"{kl_weight:.3f}\"\n",
    "    })\n",
    "\n",
    "    scheduler_main.step()\n",
    "\n",
    "model.eval()\n",
    "z_all = torch.zeros((len(adata), z_dim), device=device)\n",
    "ae_all_global = torch.zeros((len(adata), model.hidden), device=device)\n",
    "aq_all_global = torch.zeros((len(adata), model.hidden), device=device) \n",
    "val = model.values(torch.eye(model.kv_n, device=device))  \n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(test_loader):\n",
    "        indices = batch_data[-1]  \n",
    "        m_values = batch_data[3]\n",
    "        unique_m = m_values.unique()\n",
    "\n",
    "        for m_curr in unique_m:\n",
    "            mask = (m_values == m_curr)\n",
    "            if not mask.any():\n",
    "                continue\n",
    "\n",
    "            sub_batch = [d[mask] for d in batch_data]\n",
    "            m1, m2, m3, m_tensor, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "            z, p1, p2, p3, qz, pz, a1_batch, a2_batch, a3_batch, aq_batch, ae_batch = model(\n",
    "                m1, m2, m3, int(m_curr.item()), batch_tensor\n",
    "            )\n",
    "\n",
    "            z_all[idx.long()] = z\n",
    "            ae_all_global[idx.long()] = ae_batch\n",
    "            aq_all_global[idx.long()] = aq_batch  \n",
    "\n",
    "adata.obsm['latent'] = z_all.cpu().numpy()\n",
    "adata.write_h5ad(output_path)\n",
    "\n",
    "torch.save(ae_all_global.cpu(), os.path.join(t_dir, \"trimodal_e.pt\"))\n",
    "torch.save(aq_all_global.cpu(), os.path.join(t_dir, \"trimodal_q.pt\")) \n",
    "torch.save(val.cpu(), os.path.join(t_dir, \"trimodal_v.pt\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
