{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This Jupyter notebook contains the source code for multimodal mapping and imputation in the MultiGAI framework.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Distribution, Normal, constraints\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import scanpy as sc\n",
    "from scipy.sparse import issparse\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    # Set Python built-in random seed\n",
    "    random.seed(seed)  \n",
    "    \n",
    "    # Set NumPy random seed\n",
    "    np.random.seed(seed) \n",
    "    \n",
    "    # Set PyTorch CPU random seed\n",
    "    torch.manual_seed(seed) \n",
    "    \n",
    "    # Set PyTorch GPU random seed (current device)\n",
    "    torch.cuda.manual_seed(seed)  \n",
    "    \n",
    "    # Set PyTorch GPU random seed (all devices)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    \n",
    "    # Ensure deterministic behavior for CuDNN\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    \n",
    "    # Disable CuDNN auto-tuner to guarantee reproducibility\n",
    "    torch.backends.cudnn.benchmark = False  \n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroInflatedNegativeBinomial(Distribution):\n",
    "    \"\"\"\n",
    "    Zero-Inflated Negative Binomial (ZINB) distribution.\n",
    "\n",
    "    This distribution is commonly used to model over-dispersed count data\n",
    "    with excessive zeros, such as scRNA-seq gene expression counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Constraints on distribution parameters\n",
    "    arg_constraints = {\n",
    "        \"mu\": constraints.greater_than_eq(0),      # Mean of the NB distribution\n",
    "        \"theta\": constraints.greater_than_eq(0),   # Inverse dispersion parameter\n",
    "        \"zi_logits\": constraints.real,              # Logits for zero-inflation probability\n",
    "        \"scale\": constraints.greater_than_eq(0),   # Optional scaling factor (e.g. library size)\n",
    "    }\n",
    "\n",
    "    # Support of the distribution: non-negative integers\n",
    "    support = constraints.nonnegative_integer\n",
    "\n",
    "    def __init__(self, mu, theta, zi_logits, scale, eps=1e-8, validate_args=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        mu : torch.Tensor\n",
    "            Mean of the Negative Binomial distribution.\n",
    "        theta : torch.Tensor\n",
    "            Inverse dispersion parameter of the NB distribution.\n",
    "        zi_logits : torch.Tensor\n",
    "            Logits controlling the zero-inflation probability.\n",
    "        scale : torch.Tensor\n",
    "            Scaling factor applied to the mean (e.g. size factor).\n",
    "        eps : float\n",
    "            Small constant for numerical stability.\n",
    "        validate_args : bool\n",
    "            Whether to validate distribution arguments.\n",
    "        \"\"\"\n",
    "        self.mu = mu\n",
    "        self.theta = theta\n",
    "        self.zi_logits = zi_logits\n",
    "        self.scale = scale \n",
    "        self.eps = eps\n",
    "\n",
    "        # Initialize base Distribution class\n",
    "        super().__init__(validate_args=validate_args)\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"\n",
    "        Compute log-probability of observed counts under ZINB.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Observed count data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Log-likelihood of each observation.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert zero-inflation logits to probability\n",
    "        pi = torch.sigmoid(self.zi_logits)\n",
    "\n",
    "        # Log-probability under the Negative Binomial distribution\n",
    "        log_nb = (\n",
    "            torch.lgamma(x + self.theta)\n",
    "            - torch.lgamma(self.theta)\n",
    "            - torch.lgamma(x + 1)\n",
    "            + self.theta * torch.log(self.theta + self.eps)\n",
    "            + x * torch.log(self.mu + self.eps)\n",
    "            - (x + self.theta) * torch.log(self.mu + self.theta + self.eps)\n",
    "        )\n",
    "\n",
    "        # Zero-inflated mixture:\n",
    "        # - If x == 0: mixture of structural zero and NB zero\n",
    "        # - If x > 0: NB probability scaled by (1 - pi)\n",
    "        log_prob = torch.where(\n",
    "            (x == 0),\n",
    "            torch.log(pi + (1 - pi) * torch.exp(log_nb) + self.eps),\n",
    "            torch.log(1 - pi + self.eps) + log_nb,\n",
    "        )\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "class multigai(nn.Module):\n",
    "    \"\"\"\n",
    "    MultiGAI: A multi-modal generative integration model.\n",
    "\n",
    "    This model supports joint representation learning and cross-modality\n",
    "    reconstruction using attention-based latent fusion and ZINB decoders.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim1,\n",
    "        input_dim2,\n",
    "        input_dim3,\n",
    "        n_hidden,\n",
    "        hidden,\n",
    "        z_dim,\n",
    "        batch_dim,\n",
    "        q_dim=128,\n",
    "        kv_n=64,\n",
    "        dropout_rate=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # ===== Hyperparameters =====\n",
    "        self.kv_n = kv_n              # Number of key/value tokens\n",
    "        self.q_dim = q_dim            # Query embedding dimension\n",
    "        self.z_dim = z_dim            # Latent space dimension\n",
    "        self.batch_dim = batch_dim    # Batch covariate dimension\n",
    "        self.hidden = hidden          # Hidden layer width\n",
    "\n",
    "        # ===== Shared encoder constructor =====\n",
    "        def make_encoder(in_dim):\n",
    "            \"\"\"\n",
    "            Build a multi-layer MLP encoder with LayerNorm and Dropout.\n",
    "            \"\"\"\n",
    "            layers = []\n",
    "            for _ in range(n_hidden):\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_dim, hidden),\n",
    "                        nn.LayerNorm(hidden),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(dropout_rate)\n",
    "                    )\n",
    "                )\n",
    "                in_dim = hidden\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        # ===== Modality-specific encoders =====\n",
    "        self.encoder1 = make_encoder(input_dim1)\n",
    "        self.encoder2 = make_encoder(input_dim2)\n",
    "        self.encoder3 = make_encoder(input_dim3)\n",
    "\n",
    "        # ===== Projection to query space =====\n",
    "        self.q_net1 = nn.Linear(hidden, q_dim)\n",
    "        self.q_net2 = nn.Linear(hidden, q_dim)\n",
    "        self.q_net3 = nn.Linear(hidden, q_dim)\n",
    "\n",
    "        # ===== Key / Value network constructor =====\n",
    "        def make_kv(is_value):\n",
    "            \"\"\"\n",
    "            Build key/value networks for attention-based latent fusion.\n",
    "            \"\"\"\n",
    "            layers = []\n",
    "            in_dim = kv_n\n",
    "            for _ in range(n_hidden):\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        nn.Linear(in_dim, hidden),\n",
    "                        nn.LayerNorm(hidden),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(dropout_rate)\n",
    "                    )\n",
    "                )\n",
    "                in_dim = hidden\n",
    "            if not is_value:\n",
    "                layers.append(nn.Linear(hidden, q_dim))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        # ===== Modality-specific key/value banks =====\n",
    "        self.keys1 = make_kv(is_value=False)\n",
    "        self.values1 = make_kv(is_value=True)\n",
    "        self.keys2 = make_kv(is_value=False)\n",
    "        self.values2 = make_kv(is_value=True)\n",
    "        self.keys3 = make_kv(is_value=False)\n",
    "        self.values3 = make_kv(is_value=True)\n",
    "\n",
    "        # ===== Shared key/value banks =====\n",
    "        self.keys = make_kv(is_value=False)\n",
    "        self.values = make_kv(is_value=True)\n",
    "\n",
    "        # ===== Latent Gaussian parameter heads =====\n",
    "        self.m_net = nn.Linear(hidden, z_dim)   # Mean of q(z|x)\n",
    "        self.l_net = nn.Linear(hidden, z_dim)   # Log-variance of q(z|x)\n",
    "\n",
    "        # ===== Shared decoder backbone =====\n",
    "        self.decoder_base = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(z_dim + batch_dim if i == 0 else hidden + batch_dim, hidden),\n",
    "                nn.LayerNorm(hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ) for i in range(n_hidden)\n",
    "        ])\n",
    "\n",
    "        # ===== ZINB decoders for each modality =====\n",
    "        # Modality 1\n",
    "        self.fc_scale1 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim1),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout1 = nn.Linear(hidden + batch_dim, input_dim1)\n",
    "        self.fc_r1 = nn.Parameter(torch.randn(input_dim1))  # Dispersion\n",
    "\n",
    "        # Modality 2\n",
    "        self.fc_scale2 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim2),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout2 = nn.Linear(hidden + batch_dim, input_dim2)\n",
    "        self.fc_r2 = nn.Parameter(torch.randn(input_dim2))\n",
    "\n",
    "        # Modality 3\n",
    "        self.fc_scale3 = nn.Sequential(\n",
    "            nn.Linear(hidden + batch_dim, input_dim3),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.fc_dropout3 = nn.Linear(hidden + batch_dim, input_dim3)\n",
    "        self.fc_r3 = nn.Parameter(torch.randn(input_dim3))\n",
    "\n",
    "    def compute_mu_var(self, device, q1=None, q2=None, q3=None, m=None):\n",
    "        \"\"\"\n",
    "        Compute latent mean and variance using attention-based fusion\n",
    "        of modality-specific query embeddings.\n",
    "        \"\"\"\n",
    "        I = torch.eye(self.kv_n, device=device)   # Identity tokens\n",
    "        scale = math.sqrt(self.q_dim)\n",
    "\n",
    "        attn1 = attn2 = attn3 = None\n",
    "\n",
    "        # ===== Modality-pair attention fusion =====\n",
    "        if m == 12:\n",
    "            ker1, val1 = self.keys1(I), self.values1(I)\n",
    "            ker2, val2 = self.keys2(I), self.values2(I)\n",
    "\n",
    "            attn1 = torch.softmax((q1 @ ker1.T) / scale, dim=-1) @ val1\n",
    "            attn2 = torch.softmax((q2 @ ker2.T) / scale, dim=-1) @ val2\n",
    "\n",
    "            ae = (attn1 + attn2) / 2.0\n",
    "\n",
    "        elif m == 13:\n",
    "            ker1, val1 = self.keys1(I), self.values1(I)\n",
    "            ker3, val3 = self.keys3(I), self.values3(I)\n",
    "\n",
    "            attn1 = torch.softmax((q1 @ ker1.T) / scale, dim=-1) @ val1\n",
    "            attn3 = torch.softmax((q3 @ ker3.T) / scale, dim=-1) @ val3\n",
    "\n",
    "            ae = (attn1 + attn3) / 2.0\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported modality m={m}\")\n",
    "\n",
    "        # ===== Shared attention refinement =====\n",
    "        ker, val = self.keys(I), self.values(I)\n",
    "        attn = torch.softmax((ae @ ker.T) / scale, dim=-1) @ val\n",
    "\n",
    "        # ===== Latent Gaussian parameters =====\n",
    "        mu = self.m_net(attn)\n",
    "        logvar = self.l_net(attn)\n",
    "        var = torch.exp(logvar) + 1e-8\n",
    "\n",
    "        return mu, var, attn1, attn2, attn3, ae, attn\n",
    "\n",
    "    def decode_from_z(self, dz, m1, m2, m3, m, batch):\n",
    "        \"\"\"\n",
    "        Decode latent variables into modality-specific ZINB distributions.\n",
    "        \"\"\"\n",
    "        for layer in self.decoder_base:\n",
    "            dz = torch.cat([dz, batch], dim=1)\n",
    "            dz = layer(dz)\n",
    "\n",
    "        final = torch.cat([dz, batch], dim=1)\n",
    "\n",
    "        p1 = p2 = p3 = None\n",
    "\n",
    "        if m in [12, 13]:\n",
    "            # ===== Modality 1 =====\n",
    "            scale1 = self.fc_scale1(final)\n",
    "            dropout1 = self.fc_dropout1(final)\n",
    "            library1 = torch.log(m1.sum(1, keepdim=True) + 1e-8)\n",
    "            rate1 = torch.exp(library1) * scale1\n",
    "\n",
    "            p1 = ZeroInflatedNegativeBinomial(\n",
    "                mu=rate1,\n",
    "                theta=torch.exp(self.fc_r1),\n",
    "                zi_logits=dropout1,\n",
    "                scale=scale1\n",
    "            )\n",
    "\n",
    "            # ===== Modality 2 =====\n",
    "            if m == 12:\n",
    "                scale2 = self.fc_scale2(final)\n",
    "                dropout2 = self.fc_dropout2(final)\n",
    "                library2 = torch.log(m2.sum(1, keepdim=True) + 1e-8)\n",
    "                rate2 = torch.exp(library2) * scale2\n",
    "\n",
    "                p2 = ZeroInflatedNegativeBinomial(\n",
    "                    mu=rate2,\n",
    "                    theta=torch.exp(self.fc_r2),\n",
    "                    zi_logits=dropout2,\n",
    "                    scale=scale2\n",
    "                )\n",
    "\n",
    "            # ===== Modality 3 =====\n",
    "            if m == 13:\n",
    "                scale3 = self.fc_scale3(final)\n",
    "                dropout3 = self.fc_dropout3(final)\n",
    "                library3 = torch.log(m3.sum(1, keepdim=True) + 1e-8)\n",
    "                rate3 = torch.exp(library3) * scale3\n",
    "\n",
    "                p3 = ZeroInflatedNegativeBinomial(\n",
    "                    mu=rate3,\n",
    "                    theta=torch.exp(self.fc_r3),\n",
    "                    zi_logits=dropout3,\n",
    "                    scale=scale3\n",
    "                )\n",
    "\n",
    "        return p1, p2, p3\n",
    "\n",
    "    def forward(self, m1, m2, m3, m, batch):\n",
    "        \"\"\"\n",
    "        Forward pass of MultiGAI.\n",
    "        \"\"\"\n",
    "        device = batch.device\n",
    "        batch_size = m1.size(0)\n",
    "\n",
    "        # ===== Encode =====\n",
    "        q1 = q2 = q3 = None\n",
    "        if m in [12, 13]:\n",
    "            e1 = self.encoder1(m1)\n",
    "            q1 = self.q_net1(e1)\n",
    "\n",
    "            if m == 12:\n",
    "                e2 = self.encoder2(m2)\n",
    "                q2 = self.q_net2(e2)\n",
    "\n",
    "            if m == 13:\n",
    "                e3 = self.encoder3(m3)\n",
    "                q3 = self.q_net3(e3)\n",
    "\n",
    "        # ===== Latent inference =====\n",
    "        mu, var, a1, a2, a3, aq, ae = self.compute_mu_var(device, q1, q2, q3, m)\n",
    "        var = torch.clamp(var, min=1e-6)\n",
    "\n",
    "        qz = Normal(mu, var.sqrt())\n",
    "        z = qz.rsample()\n",
    "        pz = Normal(torch.zeros_like(z), torch.ones_like(z))\n",
    "\n",
    "        # ===== Decode =====\n",
    "        p1, p2, p3 = self.decode_from_z(z, m1, m2, m3, m, batch)\n",
    "\n",
    "        return z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae\n",
    "\n",
    "    def loss_function(self, m1, m2, m3, m, p1, p2, p3, q, p, a1, a2, a3, w):\n",
    "        \"\"\"\n",
    "        Compute total loss:\n",
    "        reconstruction + KL divergence + cosine alignment loss.\n",
    "        \"\"\"\n",
    "        device = m1.device\n",
    "        cos_loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "        if m == 12:\n",
    "            reconst_loss = (\n",
    "                -p1.log_prob(m1).sum(-1).mean()\n",
    "                -p2.log_prob(m2).sum(-1).mean()\n",
    "            )\n",
    "            cos_loss = (1 - F.cosine_similarity(a1, a2, dim=1)).mean()\n",
    "\n",
    "        elif m == 13:\n",
    "            reconst_loss = (\n",
    "                -p1.log_prob(m1).sum(-1).mean()\n",
    "                -p3.log_prob(m3).sum(-1).mean()\n",
    "            )\n",
    "            cos_loss = (1 - F.cosine_similarity(a1, a3, dim=1)).mean()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported modality m={m}\")\n",
    "\n",
    "        kl = torch.distributions.kl_divergence(q, p).sum(dim=-1).mean()\n",
    "\n",
    "        loss = reconst_loss + w * kl + cos_loss\n",
    "        return loss, reconst_loss, kl, cos_loss\n",
    "\n",
    "class M2L(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=1024, dropout_p=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),        \n",
    "            nn.Linear(hidden_dim, hidden_dim // 2), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_p),        \n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class MultiOmicsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for multi-omics data.\n",
    "\n",
    "    Each sample contains:\n",
    "    - Three modality feature vectors (m1, m2, m3)\n",
    "    - A modality indicator m\n",
    "    - A batch covariate\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        self.m1_data = args[0]     # Modality 1 data (e.g., scRNA-seq)\n",
    "        self.m2_data = args[1]     # Modality 2 data (e.g., scATAC-seq)\n",
    "        self.m3_data = args[2]     # Modality 3 data (e.g., ADT)\n",
    "        self.m_data = args[3]      # Modality indicator (12 or 13)\n",
    "        self.batch_data = args[4]  # Batch labels / covariates\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of samples\n",
    "        return len(self.batch_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert each modality to float tensor\n",
    "        m1 = torch.tensor(self.m1_data[idx], dtype=torch.float32).squeeze(0)\n",
    "        m2 = torch.tensor(self.m2_data[idx], dtype=torch.float32).squeeze(0)\n",
    "        m3 = torch.tensor(self.m3_data[idx], dtype=torch.float32).squeeze(0)\n",
    "\n",
    "        # Modality combination indicator\n",
    "        m = torch.tensor(self.m_data[idx], dtype=torch.float32).squeeze(0)\n",
    "\n",
    "        # Batch covariate\n",
    "        batch = self.batch_data[idx]\n",
    "\n",
    "        return m1, m2, m3, m, batch, idx   \n",
    "    \n",
    "def rnaatacmapping(output_path, adata, *args, num_epochs=200):\n",
    "\n",
    "    \"\"\"\n",
    "    Functionality:\n",
    "    --------------\n",
    "    Train a latent space using Multiome modality (joint RNA + ATAC) with the MultiGAI model,\n",
    "    then map RNA and ATAC modalities into this latent space. The resulting latent representations\n",
    "    can be used for downstream analyses or imputation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path : str\n",
    "        Path to save the resulting h5ad file.\n",
    "    adata : AnnData\n",
    "        Input AnnData object containing RNA and ATAC data; also serves as the container\n",
    "        to store the computed latent variables.\n",
    "    *args : tuple\n",
    "        Model parameters, including:\n",
    "        n_hidden : int\n",
    "            Number of hidden layers for all neural network components (encoder & decoder)\n",
    "        hidden : int\n",
    "            Hidden dimension for all layers in the network\n",
    "        z_dim : int\n",
    "            Dimension of the latent space\n",
    "        q_dim : int\n",
    "            Dimension of the query vector (Q) in attention\n",
    "        kv_n : int\n",
    "            Number of key-value (K-V) pairs in attention\n",
    "    num_epochs : int, optional\n",
    "        Number of training epochs (default: 200)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Results (latent variables) are stored in adata.obsm and written to the specified h5ad file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack model parameters\n",
    "    n_hidden, hidden, z_dim, q_dim, kv_n = args\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Separate RNA and ATAC data\n",
    "    rna = adata[:, adata.var['feature_types'] == 'GEX'].copy()\n",
    "    atac = adata[:, adata.var['feature_types'] == 'ATAC'].copy()\n",
    "\n",
    "    # Use paired cells as training set\n",
    "    rna_t  = rna[rna.obs_names[rna.obs[\"Modality\"] == \"multiome\"]].copy()\n",
    "    atac_t = atac[atac.obs_names[atac.obs[\"Modality\"] == \"multiome\"]].copy()\n",
    "    z1_index = rna_t.obs_names.values \n",
    "\n",
    "    # Get count matrices\n",
    "    rna_t_d, atac_t_d = rna_t.layers['counts'], atac_t.layers['counts']\n",
    "    adt_t_d = np.zeros((rna_t_d.shape[0], 1))  # Initialize ADT data as zeros\n",
    "    rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], 1\n",
    "\n",
    "    # Convert sparse matrix to dense if necessary\n",
    "    if issparse(rna_t_d): rna_t_d = rna_t_d.toarray()\n",
    "    if issparse(atac_t_d): atac_t_d = atac_t_d.toarray()\n",
    "    if issparse(adt_t_d): adt_t_d = adt_t_d.toarray()\n",
    "\n",
    "    # Map modality to numeric vector\n",
    "    modality_map = {'multiome': 12, 'cite': 13}\n",
    "    modality_vector = rna_t.obs['Modality'].map(modality_map)\n",
    "    modality_d = modality_vector.to_numpy().astype(float)\n",
    "\n",
    "    # One-hot encode batch\n",
    "    batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long()\n",
    "    batch_encoded = torch.nn.functional.one_hot(batch_indices)\n",
    "    batch_dim = batch_encoded.shape[1]\n",
    "\n",
    "    # Construct training dataset\n",
    "    dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded)\n",
    "    train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True)\n",
    "    test1_loader = DataLoader(dataset_t, batch_size=512, shuffle=False)\n",
    "\n",
    "    # === Initialize model ===\n",
    "    model = multigai(rna_dim, atac_dim, adt_dim, n_hidden, hidden, z_dim, batch_encoded.shape[1], q_dim, kv_n).to(device)\n",
    "    optimizer_main = Adam(model.parameters(), lr=0.001)\n",
    "    scheduler_main = torch.optim.lr_scheduler.StepLR(optimizer_main, step_size=50, gamma=0.9)\n",
    "\n",
    "    # === Train main model ===\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        kl_weight = 0.0 if epoch < 100 else 0.1  # KL loss not weighted for first 100 epochs\n",
    "        model.train()\n",
    "        for batch_data in train_loader:\n",
    "            optimizer_main.zero_grad()\n",
    "            m_values = batch_data[3]  # modality labels\n",
    "            unique_m = m_values.unique()  # all modalities in this batch\n",
    "\n",
    "            # Split sub-batch by modality\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, m_tensor, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "                    # Forward pass\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3, int(m_curr.item()), batch_tensor\n",
    "                    )\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss, reconst_loss, kl_loss, cos_loss = model.loss_function(\n",
    "                        m1, m2, m3, int(m_curr.item()), p1, p2, p3, qz, pz, a1, a2, a3, kl_weight\n",
    "                    )\n",
    "                    loss.backward()\n",
    "                    optimizer_main.step()\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "        scheduler_main.step()\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader):.4f}, KL_weight: {kl_weight}\")\n",
    "\n",
    "    # === Extract latent embeddings ===\n",
    "    model.eval()\n",
    "    z1_list, a1_list, a2_list, ae_list = [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test1_loader:\n",
    "            m_values = batch_data[3]\n",
    "            unique_m = m_values.unique()\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, _, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3, int(m_curr.item()), batch_tensor\n",
    "                    )\n",
    "            z1_list.append(z)\n",
    "            a1_list.append(a1)\n",
    "            a2_list.append(a2)\n",
    "            ae_list.append(ae)\n",
    "\n",
    "    # Concatenate all batches\n",
    "    z1_tensor  = torch.cat(z1_list, dim=0)\n",
    "    a1_tensor  = torch.cat(a1_list, dim=0)\n",
    "    a2_tensor  = torch.cat(a2_list, dim=0)\n",
    "    ae_tensor  = torch.cat(ae_list, dim=0)\n",
    "\n",
    "    # === MLP distillation ===\n",
    "    def train_mlp(x_tensor, y_tensor, input_dim, output_dim, epochs=200):\n",
    "        dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "        mlp = M2L(input_dim, output_dim).to(device)\n",
    "        optimizer = Adam(mlp.parameters(), lr=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        mlp.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for x, y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = mlp(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            if (epoch+1) % 50 == 0:\n",
    "                print(f\"[MLP Epoch {epoch+1}/{epochs}] Loss: {running_loss/len(loader):.4f}\")\n",
    "        return mlp\n",
    "\n",
    "    # Train MLP to map each modality's intermediate embedding to joint embedding\n",
    "    mlp1 = train_mlp(a1_tensor, ae_tensor, a1_tensor.shape[1], ae_tensor.shape[1])\n",
    "    mlp2 = train_mlp(a2_tensor, ae_tensor, a2_tensor.shape[1], ae_tensor.shape[1])\n",
    "\n",
    "    def infer_mlp(mlp, x_tensor):\n",
    "        # Inference in batches\n",
    "        batch_size = 512\n",
    "        preds = []\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, x_tensor.shape[0], batch_size):\n",
    "                batch = x_tensor[i:i+batch_size]\n",
    "                preds.append(mlp(batch))\n",
    "        return torch.cat(preds, dim=0)\n",
    "\n",
    "    # Prepare RNA tensor\n",
    "    gene_mask = adata.var['feature_types'] == 'GEX'\n",
    "    rna_cells = adata.obs['Modality'] == 'rna'\n",
    "    x_gene_np = adata[rna_cells, :][:, gene_mask].layers['counts']\n",
    "    x_gene_tensor = torch.tensor(x_gene_np.toarray() if issparse(x_gene_np) else x_gene_np,\n",
    "                                 dtype=torch.float32, device=device)\n",
    "    z2_index = adata[rna_cells, :].obs_names.values  # RNA cell names\n",
    "\n",
    "    # Prepare ATAC tensor\n",
    "    peaks_mask = adata.var['feature_types'] == 'ATAC'\n",
    "    atac_cells = adata.obs['Modality'] == 'atac'\n",
    "    x_peaks_np = adata[atac_cells, :][:, peaks_mask].layers['counts']\n",
    "    x_peaks_tensor = torch.tensor(x_peaks_np.toarray() if issparse(x_peaks_np) else x_peaks_np,\n",
    "                                  dtype=torch.float32, device=device)\n",
    "    z3_index = adata[atac_cells, :].obs_names.values  # ATAC cell names\n",
    "\n",
    "    # Map x1 → a1, x2 → a2\n",
    "    def x_to_a1_a2(x_gene_tensor, x_peaks_tensor, model):\n",
    "        batch_size = 512\n",
    "        a1_list, a2_list = [], []\n",
    "        I = torch.eye(model.kv_n, device=x_gene_tensor.device)\n",
    "        scale = math.sqrt(model.q_dim)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # RNA\n",
    "            for i in range(0, x_gene_tensor.shape[0], batch_size):\n",
    "                batch = x_gene_tensor[i:i+batch_size]\n",
    "                e1 = model.encoder1(batch)\n",
    "                q1 = model.q_net1(e1)\n",
    "                ker = model.keys1(I)\n",
    "                var = model.values1(I)\n",
    "                attn_logits1 = (q1 @ ker.T) / scale\n",
    "                attn_weights1 = torch.softmax(attn_logits1, dim=-1)\n",
    "                a1_list.append(attn_weights1 @ var)\n",
    "            # ATAC\n",
    "            for i in range(0, x_peaks_tensor.shape[0], batch_size):\n",
    "                batch = x_peaks_tensor[i:i+batch_size]\n",
    "                e2 = model.encoder2(batch)\n",
    "                q2 = model.q_net2(e2)\n",
    "                kea = model.keys2(I)\n",
    "                vaa = model.values2(I)\n",
    "                attn_logits2 = (q2 @ kea.T) / scale\n",
    "                attn_weights2 = torch.softmax(attn_logits2, dim=-1)\n",
    "                a2_list.append(attn_weights2 @ vaa)\n",
    "        a1 = torch.cat(a1_list, dim=0)\n",
    "        a2 = torch.cat(a2_list, dim=0)\n",
    "        return a1, a2\n",
    "     \n",
    "    a1, a2 = x_to_a1_a2(x_gene_tensor, x_peaks_tensor, model)\n",
    "    e1_tensor = infer_mlp(mlp1, a1)\n",
    "    e2_tensor = infer_mlp(mlp2, a2)\n",
    "\n",
    "    # Map e → z\n",
    "    def e_to_z(e_tensor):\n",
    "        batch_size = 512\n",
    "        z_list = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, e_tensor.shape[0], batch_size):\n",
    "                batch = e_tensor[i:i+batch_size]\n",
    "                mu = model.m_net(batch)\n",
    "                logvar = model.l_net(batch)\n",
    "                var = torch.exp(logvar) + 1e-8\n",
    "                qz = Normal(mu, var.sqrt())\n",
    "                z_list.append(qz.rsample())\n",
    "        return torch.cat(z_list, dim=0)\n",
    "\n",
    "    z2_tensor = e_to_z(e1_tensor)\n",
    "    z3_tensor = e_to_z(e2_tensor)\n",
    "\n",
    "    latent_dim = z1_tensor.shape[1]\n",
    "    latent_matrix = torch.full((adata.n_obs, latent_dim), float('nan'), device=device)\n",
    "\n",
    "    # Build cell_name -> row index mapping\n",
    "    adata_index = adata.obs_names.values\n",
    "    adata_mapping = {cell: i for i, cell in enumerate(adata_index)}\n",
    "\n",
    "    # Fill latent matrix\n",
    "    def fill_latent(tensor, tensor_index):\n",
    "        idx = [adata_mapping[cell] for cell in tensor_index]\n",
    "        latent_matrix[idx, :] = tensor\n",
    "\n",
    "    fill_latent(z1_tensor, z1_index) # Multiome\n",
    "    fill_latent(z2_tensor, z2_index) # RNA\n",
    "    fill_latent(z3_tensor, z3_index) # ATAC\n",
    "\n",
    "    # Save latent embeddings to adata.obsm\n",
    "    adata.obsm['latent'] = latent_matrix.cpu().numpy()\n",
    "    adata.write_h5ad(output_path)\n",
    "\n",
    "def rnaadtmapping(output_path, adata, *args, num_epochs=200):\n",
    "    \n",
    "    \"\"\"\n",
    "    Functionality:\n",
    "    --------------\n",
    "    Train a latent space using CITE modality (ADT + RNA) with MultiGAI model,\n",
    "    then map RNA and ADT modalities into this latent space. The resulting latent\n",
    "    representations can be used for downstream analyses or imputation.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path : str\n",
    "        Path to save the resulting h5ad file.\n",
    "    adata : AnnData\n",
    "        Input AnnData object containing RNA and ADT data; also serves as the\n",
    "        container to store the computed latent variables.\n",
    "    *args : tuple\n",
    "        Model parameters, including:\n",
    "        n_hidden : int\n",
    "            Number of hidden layers for all neural network components (encoder & decoder)\n",
    "        hidden : int\n",
    "            Hidden dimension for all layers in the network\n",
    "        z_dim : int\n",
    "            Dimension of the latent space\n",
    "        q_dim : int\n",
    "            Dimension of the query vector (Q) in attention\n",
    "        kv_n : int\n",
    "            Number of key-value (K-V) pairs in attention\n",
    "    num_epochs : int, optional\n",
    "        Number of training epochs (default: 200)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Results (latent variables) are stored in adata.obsm and written to the specified h5ad file.\n",
    "    \"\"\"\n",
    "\n",
    "    # multigai parameters\n",
    "    n_hidden, hidden, z_dim, q_dim, kv_n = args\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Split RNA and ADT modalities\n",
    "    rna = adata[:, adata.var['feature_types'] == 'GEX'].copy()\n",
    "    adt = adata[:, adata.var['feature_types'] == 'ADT'].copy()\n",
    "\n",
    "    # Select CITE cells for training\n",
    "    rna_t  = rna[rna.obs_names[rna.obs[\"Modality\"] == \"cite\"]].copy()\n",
    "    adt_t = adt[adt.obs_names[adt.obs[\"Modality\"] == \"cite\"]].copy()\n",
    "\n",
    "    z1_index = rna_t.obs_names.values\n",
    "\n",
    "    # Extract raw count matrices\n",
    "    rna_t_d, adt_t_d = rna_t.layers['counts'], adt_t.layers['counts']\n",
    "    atac_t_d = np.zeros((rna_t_d.shape[0], 1))  # placeholder for unused modality\n",
    "    rna_dim, atac_dim, adt_dim = rna.shape[1], 1, adt.shape[1]\n",
    "    if issparse(rna_t_d): rna_t_d = rna_t_d.toarray()\n",
    "    if issparse(atac_t_d): atac_t_d = atac_t_d.toarray()\n",
    "    if issparse(adt_t_d): adt_t_d = adt_t_d.toarray() \n",
    "\n",
    "    # Map modality to numeric IDs\n",
    "    modality_map = {\n",
    "        'multiome': 12,\n",
    "        'cite': 13,\n",
    "    }\n",
    "    modality_vector = rna_t.obs['Modality'].map(modality_map)\n",
    "    modality_d = modality_vector.to_numpy().astype(float)\n",
    "\n",
    "    # One-hot encode batch information\n",
    "    batch_indices = torch.from_numpy(rna_t.obs['batch'].astype('category').cat.codes.values).long()\n",
    "    batch_encoded = torch.nn.functional.one_hot(batch_indices)\n",
    "    batch_dim = batch_encoded.shape[1]\n",
    "\n",
    "    # Create dataset and data loaders\n",
    "    dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded)\n",
    "    train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True)\n",
    "    test1_loader = DataLoader(dataset_t, batch_size=512, shuffle=False)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = multigai(rna_dim, atac_dim, adt_dim, n_hidden, hidden, z_dim, batch_encoded.shape[1], q_dim, kv_n).to(device)\n",
    "    optimizer_main = Adam(model.parameters(), lr=0.001)\n",
    "    scheduler_main = torch.optim.lr_scheduler.StepLR(optimizer_main, step_size=50, gamma=0.9)\n",
    "\n",
    "    # Train the main model\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        kl_weight = 0.0 if epoch < 100 else 0.1\n",
    "        model.train()\n",
    "        for batch_data in train_loader:\n",
    "            optimizer_main.zero_grad()\n",
    "\n",
    "            m_values = batch_data[3]  # modality indicator\n",
    "            unique_m = m_values.unique()\n",
    "\n",
    "            # Split batch by modality\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, m_tensor, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "                    # Forward pass\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3, int(m_curr.item()), batch_tensor\n",
    "                    )\n",
    "                    # Compute loss\n",
    "                    loss, reconst_loss, kl_loss, cos_loss = model.loss_function(\n",
    "                        m1, m2, m3, int(m_curr.item()), p1, p2, p3, qz, pz, a1, a2, a3, kl_weight\n",
    "                    )\n",
    "                    loss.backward()\n",
    "                    optimizer_main.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "        scheduler_main.step()\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader):.4f}, KL_weight: {kl_weight}\")\n",
    "\n",
    "    model.eval()\n",
    "    z1_list, a1_list, a3_list, ae_list = [], [], [], []\n",
    "\n",
    "    # Extract embeddings for CITE cells\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test1_loader:\n",
    "            m_values = batch_data[3]\n",
    "            unique_m = m_values.unique()\n",
    "\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, _, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "                    # Forward pass\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3, int(m_curr.item()), batch_tensor\n",
    "                    )\n",
    "            \n",
    "            # Collect outputs\n",
    "            z1_list.append(z)\n",
    "            a1_list.append(a1)\n",
    "            a3_list.append(a3)\n",
    "            ae_list.append(ae)\n",
    "\n",
    "    # Concatenate into a single tensor\n",
    "    z1_tensor  = torch.cat(z1_list, dim=0)\n",
    "    a1_tensor  = torch.cat(a1_list, dim=0)\n",
    "    a3_tensor  = torch.cat(a3_list, dim=0)\n",
    "    ae_tensor  = torch.cat(ae_list, dim=0)\n",
    "\n",
    "    # Train MLPs\n",
    "    def train_mlp(x_tensor, y_tensor, input_dim, output_dim, epochs=200):\n",
    "        dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "        mlp = M2L(input_dim, output_dim).to(device)\n",
    "        optimizer = Adam(mlp.parameters(), lr=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        mlp.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for x, y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = mlp(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            if (epoch+1) % 50 == 0:\n",
    "                print(f\"[MLP Epoch {epoch+1}/{epochs}] Loss: {running_loss/len(loader):.4f}\")\n",
    "        return mlp\n",
    "\n",
    "    # Train MLP to map intermediate embeddings to joint latent\n",
    "    mlp1 = train_mlp(a1_tensor, ae_tensor, a1_tensor.shape[1], ae_tensor.shape[1])  # RNA\n",
    "    mlp2 = train_mlp(a3_tensor, ae_tensor, a3_tensor.shape[1], ae_tensor.shape[1])  # ADT\n",
    "\n",
    "    def infer_mlp(mlp, x_tensor):\n",
    "        batch_size = 512\n",
    "        preds = []\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, x_tensor.shape[0], batch_size):\n",
    "                batch = x_tensor[i:i+batch_size]\n",
    "                preds.append(mlp(batch))\n",
    "        return torch.cat(preds, dim=0)\n",
    "\n",
    "    # Prepare RNA and ADT data for inference\n",
    "    gene_mask = adata.var['feature_types'] == 'GEX'\n",
    "    rna_cells = adata.obs['Modality'] == 'rna'\n",
    "    x_gene_np = adata[rna_cells, :][:, gene_mask].layers['counts']\n",
    "    x_gene_tensor = torch.tensor(\n",
    "        x_gene_np.toarray() if issparse(x_gene_np) else x_gene_np,\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    z2_index = adata[rna_cells, :].obs_names.values\n",
    "\n",
    "    protein_mask = adata.var['feature_types'] == 'ADT'\n",
    "    adt_cells = adata.obs['Modality'] == 'adt'\n",
    "    x_adt_np = adata[adt_cells, :][:, protein_mask].layers['counts']\n",
    "    x_adt_tensor = torch.tensor(\n",
    "        x_adt_np.toarray() if issparse(x_adt_np) else x_adt_np,\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    z3_index = adata[adt_cells, :].obs_names.values\n",
    "\n",
    "    # Map x1 → a1, x3 → a3\n",
    "    def x_to_a1_a3(x_gene_tensor, x_adt_tensor, model):\n",
    "        batch_size = 512\n",
    "        a1_list = []\n",
    "        a3_list = []\n",
    "\n",
    "        I = torch.eye(model.kv_n, device=x_gene_tensor.device)\n",
    "        scale = math.sqrt(model.q_dim)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, x_gene_tensor.shape[0], batch_size):\n",
    "                batch = x_gene_tensor[i:i+batch_size]\n",
    "                e1 = model.encoder1(batch)\n",
    "                q1 = model.q_net1(e1)\n",
    "                ker = model.keys1(I)\n",
    "                var = model.values1(I)\n",
    "                attn_logits1 = (q1 @ ker.T) / scale\n",
    "                attn_weights1 = torch.softmax(attn_logits1, dim=-1)\n",
    "                a1_list.append(attn_weights1 @ var)\n",
    "\n",
    "            for i in range(0, x_adt_tensor.shape[0], batch_size):\n",
    "                batch = x_adt_tensor[i:i+batch_size]\n",
    "                e3 = model.encoder3(batch)\n",
    "                q3 = model.q_net3(e3)\n",
    "                kea = model.keys3(I)\n",
    "                vaa = model.values3(I)\n",
    "                attn_logits3 = (q3 @ kea.T) / scale\n",
    "                attn_weights3 = torch.softmax(attn_logits3, dim=-1)\n",
    "                a3_list.append(attn_weights3 @ vaa)\n",
    "\n",
    "        a1 = torch.cat(a1_list, dim=0)\n",
    "        a3 = torch.cat(a3_list, dim=0)\n",
    "        return a1, a3\n",
    "\n",
    "    a1, a3 = x_to_a1_a3(x_gene_tensor, x_adt_tensor, model)\n",
    "    e1_tensor = infer_mlp(mlp1, a1)\n",
    "    e3_tensor = infer_mlp(mlp2, a3)\n",
    "\n",
    "    # Map e → z\n",
    "    def e_to_z(e_tensor):\n",
    "        batch_size = 512\n",
    "        z_list = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, e_tensor.shape[0], batch_size):\n",
    "                batch = e_tensor[i:i+batch_size]\n",
    "                mu = model.m_net(batch)\n",
    "                logvar = model.l_net(batch)\n",
    "                var = torch.exp(logvar) + 1e-8\n",
    "                qz = Normal(mu, var.sqrt())\n",
    "                z_list.append(qz.rsample())\n",
    "        return torch.cat(z_list, dim=0)\n",
    "\n",
    "    z2_tensor = e_to_z(e1_tensor)\n",
    "    z3_tensor = e_to_z(e3_tensor)\n",
    "\n",
    "    latent_dim = z1_tensor.shape[1]\n",
    "    latent_matrix = torch.full((adata.n_obs, latent_dim), float('nan'), device=device)\n",
    "\n",
    "    adata_index = adata.obs_names.values\n",
    "    adata_mapping = {cell: i for i, cell in enumerate(adata_index)}\n",
    "\n",
    "    def fill_latent(tensor, tensor_index):\n",
    "        idx = [adata_mapping[cell] for cell in tensor_index]\n",
    "        latent_matrix[idx, :] = tensor\n",
    "\n",
    "    # Fill latent matrix for different modalities\n",
    "    fill_latent(z1_tensor, z1_index)  # Multiome\n",
    "    fill_latent(z2_tensor, z2_index)  # RNA\n",
    "    fill_latent(z3_tensor, z3_index)  # ADT\n",
    "\n",
    "    # Save latent embeddings\n",
    "    adata.obsm['latent'] = latent_matrix.cpu().numpy()\n",
    "    adata.write_h5ad(output_path)\n",
    "\n",
    "def rnaatacadtmappingandimputing(output_path, rna, atac, adt, *args, num_epochs=200):\n",
    "    \n",
    "    \"\"\"\n",
    "    Functionality:\n",
    "    --------------\n",
    "    Train a latent space using Multiome and CITE modalities, then map RNA, ATAC, and ADT data\n",
    "    into this latent space. Additionally, extract predicted values for specified genes\n",
    "    (genes_of_interest) and proteins (adts_of_interest). The results are stored in\n",
    "    rna.obsm and written to an h5ad file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path : str\n",
    "        Path to save the resulting h5ad file.\n",
    "    rna : AnnData\n",
    "        RNA AnnData object; also used as the container to store latent variables\n",
    "        and predicted gene/protein values.\n",
    "    atac : AnnData\n",
    "        ATAC AnnData object.\n",
    "    adt : AnnData\n",
    "        ADT (CITE-seq) AnnData object.\n",
    "    *args : tuple\n",
    "        Model parameters, including:\n",
    "        n_hidden : int\n",
    "            Number of hidden layers for all neural network components (encoder & decoder)\n",
    "        hidden : int\n",
    "            Hidden dimension for all layers in the network\n",
    "        z_dim : int\n",
    "            Dimension of the latent space\n",
    "        q_dim : int\n",
    "            Dimension of the query vector (Q) in attention\n",
    "        kv_n : int\n",
    "            Number of key-value (K-V) pairs in attention\n",
    "        genes_of_interest : list[str]\n",
    "            List of genes to extract predicted values for\n",
    "        peaks_of_interest : list[str]\n",
    "            List of peaks to extract predicted values for\n",
    "        adts_of_interest : list[str]\n",
    "            List of ADT proteins to extract predicted values for\n",
    "    num_epochs : int, optional\n",
    "        Number of training epochs for the main model (default: 200)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Results are stored in rna.obsm and written to the specified h5ad file.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_hidden, hidden, z_dim, q_dim, kv_n, genes_of_interest, peaks_of_interest, adts_of_interest = args\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    z1_index = rna.obs_names[rna.obs[\"Modality\"] == \"multiome\"].tolist()\n",
    "    z2_index = rna.obs_names[rna.obs[\"Modality\"] == \"cite\"].tolist()\n",
    "\n",
    "    all_index = z1_index + z2_index\n",
    "\n",
    "    rna_t_d  = rna[all_index].layers['counts']\n",
    "    atac_t_d = atac[all_index].layers['counts']\n",
    "    adt_t_d  = adt[all_index].layers['counts']\n",
    "\n",
    "    rna_dim, atac_dim, adt_dim = rna.shape[1], atac.shape[1], adt.shape[1]\n",
    "\n",
    "    if issparse(rna_t_d): rna_t_d = rna_t_d.toarray()\n",
    "    if issparse(atac_t_d): atac_t_d = atac_t_d.toarray()\n",
    "    if issparse(adt_t_d): adt_t_d = adt_t_d.toarray() \n",
    "\n",
    "    modality_map = {\n",
    "        'multiome': 12,\n",
    "        'cite': 13,\n",
    "    }\n",
    "\n",
    "    modality_vector = rna[all_index].obs['Modality'].map(modality_map)\n",
    "    modality_d = modality_vector.to_numpy().astype(float)\n",
    "\n",
    "    batch_indices = torch.from_numpy(rna[all_index].obs['batch'].astype('category').cat.codes.values).long()\n",
    "    batch_encoded = torch.nn.functional.one_hot(batch_indices)\n",
    "    batch_dim = batch_encoded.shape[1]\n",
    "\n",
    "    dataset_t = MultiOmicsDataset(rna_t_d, atac_t_d, adt_t_d, modality_d, batch_encoded)\n",
    "\n",
    "    train_loader = DataLoader(dataset_t, batch_size=512, shuffle=True)\n",
    "    test1_loader = DataLoader(dataset_t, batch_size=512, shuffle=False)\n",
    "\n",
    "    model = multigai(rna_dim, atac_dim, adt_dim, n_hidden, hidden, z_dim, batch_encoded.shape[1], q_dim, kv_n).to(device)\n",
    "    optimizer_main = Adam(model.parameters(), lr=0.001)\n",
    "    scheduler_main = torch.optim.lr_scheduler.StepLR(optimizer_main, step_size=50, gamma=0.9)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        kl_weight = 0.0 if epoch < 100 else 0.1\n",
    "        model.train()\n",
    "        \n",
    "        for batch_data in train_loader:\n",
    "            optimizer_main.zero_grad()\n",
    "\n",
    "            m_values = batch_data[3] \n",
    "            unique_m = m_values.unique().tolist()  \n",
    "            random.shuffle(unique_m)  \n",
    "\n",
    "            for m_curr in unique_m:\n",
    "                mask = (m_values == m_curr)\n",
    "                if mask.any():\n",
    "                    sub_batch = [d[mask] for d in batch_data]\n",
    "                    m1, m2, m3, m_tensor, batch_tensor, idx = [x.to(device) for x in sub_batch]\n",
    "\n",
    "                    z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                        m1, m2, m3, int(m_curr), batch_tensor\n",
    "                    )\n",
    "                    loss, reconst_loss, kl_loss, cos_loss = model.loss_function(\n",
    "                        m1, m2, m3, int(m_curr), p1, p2, p3, qz, pz, a1, a2, a3, kl_weight\n",
    "                    )\n",
    "                    loss.backward()\n",
    "                    optimizer_main.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "\n",
    "        scheduler_main.step()\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader):.4f}, KL_weight: {kl_weight}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    z1_dict, a1_z1_dict, a2_dict, ae_z1_dict = {}, {}, {}, {}\n",
    "    z2_dict, a1_z2_dict, a3_dict, ae_z2_dict = {}, {}, {}, {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in test1_loader:\n",
    "            m1, m2, m3, m_tensor, batch_tensor, idx = [d.to(device) for d in batch_data]\n",
    "\n",
    "            obs_names = [all_index[i] for i in idx.cpu().numpy()]\n",
    "\n",
    "            unique_m = m_tensor.unique()\n",
    "            for m_val in unique_m:\n",
    "                mask = (m_tensor == m_val)\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                m1_sub = m1[mask]\n",
    "                m2_sub = m2[mask]\n",
    "                m3_sub = m3[mask]\n",
    "                batch_sub = batch_tensor[mask]\n",
    "                obs_names_sub = [obs_names[i] for i, flag in enumerate(mask.cpu().numpy()) if flag]\n",
    "\n",
    "                z, p1, p2, p3, qz, pz, a1, a2, a3, aq, ae = model(\n",
    "                    m1_sub, m2_sub, m3_sub, int(m_val.item()), batch_sub\n",
    "                )\n",
    "\n",
    "                for i, name in enumerate(obs_names_sub):\n",
    "                    if int(m_val.item()) == 12:  # z1\n",
    "                        z1_dict[name] = z[i].unsqueeze(0)\n",
    "                        a1_z1_dict[name] = a1[i].unsqueeze(0)\n",
    "                        a2_dict[name] = a2[i].unsqueeze(0)\n",
    "                        ae_z1_dict[name] = ae[i].unsqueeze(0)\n",
    "                    elif int(m_val.item()) == 13:  # z2\n",
    "                        z2_dict[name] = z[i].unsqueeze(0)\n",
    "                        a1_z2_dict[name] = a1[i].unsqueeze(0)\n",
    "                        a3_dict[name] = a3[i].unsqueeze(0)\n",
    "                        ae_z2_dict[name] = ae[i].unsqueeze(0)\n",
    "\n",
    "    z1_tensor = torch.cat([z1_dict[name] for name in z1_index], dim=0)\n",
    "    a1_z1_tensor = torch.cat([a1_z1_dict[name] for name in z1_index], dim=0)\n",
    "    a2_tensor = torch.cat([a2_dict[name] for name in z1_index], dim=0)\n",
    "    ae_z1_tensor = torch.cat([ae_z1_dict[name] for name in z1_index], dim=0)\n",
    "\n",
    "    z2_tensor = torch.cat([z2_dict[name] for name in z2_index], dim=0)\n",
    "    a1_z2_tensor = torch.cat([a1_z2_dict[name] for name in z2_index], dim=0)\n",
    "    a3_tensor = torch.cat([a3_dict[name] for name in z2_index], dim=0)\n",
    "    ae_z2_tensor = torch.cat([ae_z2_dict[name] for name in z2_index], dim=0)\n",
    "\n",
    "    def train_mlp(x_tensor, y_tensor, input_dim, output_dim, epochs=200):\n",
    "        dataset = torch.utils.data.TensorDataset(x_tensor, y_tensor)\n",
    "        loader = DataLoader(dataset, batch_size=512, shuffle=True)\n",
    "        mlp = M2L(input_dim, output_dim).to(device)\n",
    "        optimizer = Adam(mlp.parameters(), lr=1e-3)\n",
    "        criterion = nn.MSELoss()\n",
    "        mlp.train()\n",
    "        for epoch in range(epochs):\n",
    "            running_loss = 0.0\n",
    "            for x, y in loader:\n",
    "                optimizer.zero_grad()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = mlp(x)\n",
    "                loss = criterion(y_pred, y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            if (epoch+1) % 50 == 0:\n",
    "                print(f\"[MLP Epoch {epoch+1}/{epochs}] Loss: {running_loss/len(loader):.4f}\")\n",
    "        return mlp\n",
    "\n",
    "    a1_tensor_full = torch.cat([a1_z1_tensor, a1_z2_tensor], dim=0)\n",
    "    ae_a1_full = torch.cat([ae_z1_tensor, ae_z2_tensor], dim=0)\n",
    "\n",
    "    a2_tensor_full = a2_tensor\n",
    "    ae_a2_full = ae_z1_tensor  \n",
    "    a3_tensor_full = a3_tensor\n",
    "    ae_a3_full = ae_z2_tensor  \n",
    "\n",
    "    mlp1 = train_mlp(a1_tensor_full, ae_a1_full, a1_tensor_full.shape[1], ae_a1_full.shape[1])\n",
    "    mlp2 = train_mlp(a2_tensor_full, ae_a2_full, a2_tensor_full.shape[1], ae_a2_full.shape[1])\n",
    "    mlp3 = train_mlp(a3_tensor_full, ae_a3_full, a3_tensor_full.shape[1], ae_a3_full.shape[1])\n",
    "\n",
    "    def infer_mlp(mlp, x_tensor):\n",
    "        batch_size = 512\n",
    "        preds = []\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, x_tensor.shape[0], batch_size):\n",
    "                batch = x_tensor[i:i+batch_size]\n",
    "                preds.append(mlp(batch))\n",
    "        return torch.cat(preds, dim=0)  \n",
    "\n",
    "    x_gene_np = rna[rna.obs['Modality'] == 'rna', :].layers['counts']\n",
    "    rna_cells = rna.obs['Modality'] == 'rna'\n",
    "    x_gene_tensor = torch.tensor(\n",
    "        x_gene_np.toarray() if issparse(x_gene_np) else x_gene_np,\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    z3_index = rna[rna_cells, :].obs_names.tolist()\n",
    "\n",
    "    x_peaks_np = atac[rna.obs['Modality'] == 'atac', :].layers['counts']\n",
    "    atac_cells = rna.obs['Modality'] == 'atac'\n",
    "    x_peaks_tensor = torch.tensor(\n",
    "        x_peaks_np.toarray() if issparse(x_peaks_np) else x_peaks_np,\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    z4_index = atac[atac_cells, :].obs_names.tolist()\n",
    "\n",
    "    x_adt_np = adt[rna.obs['Modality'] == 'adt', :].layers['counts']\n",
    "    adt_cells = rna.obs['Modality'] == 'adt'\n",
    "    x_adt_tensor = torch.tensor(\n",
    "        x_adt_np.toarray() if issparse(x_adt_np) else x_adt_np,\n",
    "        dtype=torch.float32, device=device\n",
    "    )\n",
    "    z5_index = adt[adt_cells, :].obs_names.tolist()\n",
    "\n",
    "    def x_to_a1_a2_a3(x_gene_tensor, x_peaks_tensor, x_adt_tensor, model):\n",
    "        batch_size = 512\n",
    "        a1_list = []\n",
    "        a2_list = []\n",
    "        a3_list = []\n",
    "\n",
    "        I = torch.eye(model.kv_n, device=x_gene_tensor.device) \n",
    "        scale = math.sqrt(model.q_dim)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for i in range(0, x_gene_tensor.shape[0], batch_size):\n",
    "                batch = x_gene_tensor[i:i+batch_size]\n",
    "                e1 = model.encoder1(batch)\n",
    "                q1 = model.q_net1(e1)\n",
    "                ker = model.keys1(I)\n",
    "                var = model.values1(I)\n",
    "                attn_logits1 = (q1 @ ker.T) / scale\n",
    "                attn_weights1 = torch.softmax(attn_logits1, dim=-1)\n",
    "                a1_list.append(attn_weights1 @ var)\n",
    "\n",
    "            for i in range(0, x_peaks_tensor.shape[0], batch_size):\n",
    "                batch = x_peaks_tensor[i:i+batch_size]\n",
    "                e2 = model.encoder2(batch)\n",
    "                q2 = model.q_net2(e2)\n",
    "                kea = model.keys2(I)\n",
    "                vaa = model.values2(I)\n",
    "                attn_logits2 = (q2 @ kea.T) / scale\n",
    "                attn_weights2 = torch.softmax(attn_logits2, dim=-1)\n",
    "                a2_list.append(attn_weights2 @ vaa)\n",
    "\n",
    "            for i in range(0, x_adt_tensor.shape[0], batch_size):\n",
    "                batch = x_adt_tensor[i:i+batch_size]\n",
    "                e3 = model.encoder3(batch)\n",
    "                q3 = model.q_net3(e3)\n",
    "                kea = model.keys3(I)\n",
    "                vaa = model.values3(I)\n",
    "                attn_logits3 = (q3 @ kea.T) / scale\n",
    "                attn_weights3 = torch.softmax(attn_logits3, dim=-1)\n",
    "                a3_list.append(attn_weights3 @ vaa)\n",
    "\n",
    "        a1 = torch.cat(a1_list, dim=0)\n",
    "        a2 = torch.cat(a2_list, dim=0)\n",
    "        a3 = torch.cat(a3_list, dim=0)\n",
    "        return a1, a2, a3\n",
    "\n",
    "    a1, a2, a3 = x_to_a1_a2_a3(x_gene_tensor, x_peaks_tensor, x_adt_tensor, model)\n",
    "    e1_tensor = infer_mlp(mlp1, a1)\n",
    "    e2_tensor = infer_mlp(mlp2, a2)\n",
    "    e3_tensor = infer_mlp(mlp3, a3)\n",
    "\n",
    "    def e_to_z(e_tensor):\n",
    "        batch_size = 512\n",
    "        z_list = []\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, e_tensor.shape[0], batch_size):\n",
    "                batch = e_tensor[i:i+batch_size]\n",
    "                mu = model.m_net(batch)\n",
    "                logvar = model.l_net(batch)\n",
    "                var = torch.exp(logvar) + 1e-8\n",
    "                qz = Normal(mu, var.sqrt())\n",
    "                z_list.append(qz.rsample())\n",
    "        return torch.cat(z_list, dim=0)  # GPU Tensor\n",
    "\n",
    "    z3_tensor = e_to_z(e1_tensor)\n",
    "    z4_tensor = e_to_z(e2_tensor)\n",
    "    z5_tensor = e_to_z(e3_tensor)\n",
    "\n",
    "    latent_dim = z1_tensor.shape[1]\n",
    "\n",
    "    latent_matrix = torch.full((rna.n_obs, latent_dim), float('nan'), device=device)\n",
    "\n",
    "    adata_index = rna.obs_names.values\n",
    "    adata_mapping = {cell: i for i, cell in enumerate(adata_index)}\n",
    "\n",
    "    def fill_latent(tensor, tensor_index):\n",
    "\n",
    "        idx = [adata_mapping[cell] for cell in tensor_index]\n",
    "        latent_matrix[idx, :] = tensor\n",
    "\n",
    "    fill_latent(z1_tensor, z1_index) # Multiome\n",
    "    fill_latent(z2_tensor, z2_index) # RNA\n",
    "    fill_latent(z3_tensor, z3_index) # ATAC\n",
    "    fill_latent(z4_tensor, z4_index) # ATAC\n",
    "    fill_latent(z5_tensor, z5_index) # ATAC\n",
    "\n",
    "    rna.obsm['latent'] = latent_matrix.cpu().numpy()\n",
    "\n",
    "    # Get the indices of genes of interest in rna.var.index\n",
    "    gene_idx = [rna.var.index.get_loc(g) for g in genes_of_interest]\n",
    "    \n",
    "    # Get the indices of peaks of interest in atac.var.index\n",
    "    peak_idx = [atac.var.index.get_loc(g) for g in peaks_of_interest]\n",
    "\n",
    "    # Get the indices of ADTs of interest in adt.var.index\n",
    "    adt_idx  = [adt.var.index.get_loc(a) for a in adts_of_interest]\n",
    "\n",
    "    # Combine genes ,peaks and ADTs into a single 'interest' list\n",
    "    interest = genes_of_interest + peaks_of_interest + adts_of_interest\n",
    "    interest_idx_map = {name: i for i, name in enumerate(interest)}  # Map name → column index\n",
    "\n",
    "    # Initialize prediction matrix with NaNs (shape: n_cells × n_features of interest)\n",
    "    pred_matrix = torch.full((rna.n_obs, len(interest)), float('nan'), device=device)\n",
    "\n",
    "    # Retrieve latent variables z and batch one-hot encoding\n",
    "    z = torch.tensor(rna.obsm['latent'], device=device)\n",
    "    batch_indices = torch.from_numpy(rna.obs['batch'].astype('category').cat.codes.values).long()\n",
    "    batch_encoded = F.one_hot(batch_indices).float().to(device)\n",
    "\n",
    "    batch_size = 512\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Process data in batches\n",
    "        for i in range(0, z.shape[0], batch_size):\n",
    "            dz = z[i:i+batch_size]  # Current batch of latent variables\n",
    "            batch_tensor = batch_encoded[i:i+dz.shape[0]].to(dz.device)  # Corresponding batch encoding\n",
    "\n",
    "            # ===== Decode latent variables to original modalities =====\n",
    "            temp = dz\n",
    "            for layer in model.decoder_base:\n",
    "                temp = torch.cat([temp, batch_tensor], dim=1)  # Concatenate batch info\n",
    "                temp = layer(temp)\n",
    "            final = torch.cat([temp, batch_tensor], dim=1)  # Final input for modality-specific heads\n",
    "\n",
    "            # RNA prediction (p1)\n",
    "            scale1 = model.fc_scale1(final)\n",
    "            dropout1 = model.fc_dropout1(final)\n",
    "            expectation1 = (1 - torch.sigmoid(dropout1)) * scale1  # Corrected expectation for RNA\n",
    "            \n",
    "            # ATAC prediction (p2)\n",
    "            scale2 = model.fc_scale2(final)\n",
    "            dropout2 = model.fc_dropout2(final)\n",
    "            expectation2 = (1 - torch.sigmoid(dropout2)) * scale2\n",
    "\n",
    "            # ADT prediction (p3)\n",
    "            scale3 = model.fc_scale3(final)\n",
    "            dropout3 = model.fc_dropout3(final)\n",
    "            expectation3 = (1 - torch.sigmoid(dropout3)) * scale3  # Corrected expectation for ADT\n",
    "\n",
    "            idx_range = list(range(i, i + dz.shape[0]))  # Indices for current batch in pred_matrix\n",
    "\n",
    "            # Store RNA predictions in pred_matrix\n",
    "            for j, g in enumerate(genes_of_interest):\n",
    "                pred_matrix[idx_range, interest_idx_map[g]] = expectation1[:, gene_idx[j]]\n",
    "            \n",
    "            # Store ATAC predictions in pred_matrix\n",
    "            for j, a in enumerate(peaks_of_interest):\n",
    "                pred_matrix[idx_range, interest_idx_map[a]] = expectation2[:, peak_idx[j]]\n",
    "\n",
    "            # Store ADT predictions in pred_matrix\n",
    "            for j, a in enumerate(adts_of_interest):\n",
    "                pred_matrix[idx_range, interest_idx_map[a]] = expectation3[:, adt_idx[j]]\n",
    "\n",
    "    # Save each feature prediction as a separate entry in rna.obsm\n",
    "    for j, name in enumerate(interest):\n",
    "        rna.obsm[name] = pred_matrix[:, j].cpu().numpy()\n",
    "\n",
    "    # Write the updated AnnData object to an h5ad file\n",
    "    rna.write_h5ad(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaatacmapping('./results/neurips-multiome-mapping.h5ad', \n",
    "               sc.read('./data/neurips-multiome/mapping.h5ad'), \n",
    "               1, 128, 30, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaadtmapping('./results/neurips-cite-mapping.h5ad', \n",
    "               sc.read('./data/neurips-cite/mapping.h5ad'), \n",
    "               1, 128, 30, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnaatacadtmappingandimputing('./results/trimodal-mappingandimputing.h5ad',\n",
    "           sc.read('./data/trimodal_mappingandimputing_rna.h5ad'), \n",
    "           sc.read('./data/trimodal_mappingandimputing_atac.h5ad'),\n",
    "           sc.read('./data/trimodal_mappingandimputing_adt.h5ad'),\n",
    "           1, 128, 30, 128, 128, [\"CD3G\", \"MS4A1\", \"FCGR3A\"], [\"chr11-118343914-118344801\"], [\"CD20\", \"CD3\", \"CD16\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multisi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
